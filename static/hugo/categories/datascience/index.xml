<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>datascience on El Baúl del programador</title>
        <link>https://elbauldelprogramador.com/categories/datascience/</link>
        <description>Recent content in datascience on El Baúl del programador</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>es-ES</language>
        <lastBuildDate>Tue, 16 Oct 2018 18:54:00 +0200</lastBuildDate>
        <image>
            <url>https://elbauldelprogramador.com/img/bio-photo-rss.png</url>
            <link>https://elbauldelprogramador.com/categories/datascience/</link>
            <title>datascience on El Baúl del programador</title>
            <width>144</width>
            <height>144</height>
        </image>
        <atom:link href="https://elbauldelprogramador.com/categories/datascience/" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Análisis y Visualización Básica de una Red Social de Twitter con Gephi</title>
            <link>https://elbauldelprogramador.com/social-mining-gephi/</link>
            <pubDate>Tue, 16 Oct 2018 18:54:00 +0200</pubDate>
            
            <guid>https://elbauldelprogramador.com/social-mining-gephi/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;Este artículo es el resultado de un ejercicio para la asignatura &lt;em&gt;Minería de
Medios Sociales&lt;/em&gt; en el máster en Ciencia de Datos de la UGR&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;análisis-de-la-red&#34;&gt;Análisis de la red&lt;/h2&gt;
&lt;p&gt;Esta red contiene un subconjunto de los seguidores de la cuenta &lt;a href=&#34;https://twitter.com/ElBaulP&#34;&gt;@elbaulp&lt;/a&gt; de Twitter, ya que por limitaciones de la API la descarga de la red de hasta segundo grado de conexión tardaba mucho.&lt;/p&gt;
&lt;p&gt;El objetivo de este análisis es identificar a los actores más influyentes, que hacen de puente entre comunidades para poder expandir el número de seguidores de @ElbaulP&lt;/p&gt;
&lt;h3 id=&#34;grado-medio&#34;&gt;Grado medio&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;N = 2132 nodos.&lt;/li&gt;
&lt;li&gt;L = 6643 enlaces&lt;/li&gt;
&lt;li&gt;Densidad = 0.001&lt;/li&gt;
&lt;li&gt;Grado medio = 3.116, lo cual quiere decir que cada nodo de la red está conectado con otros 3 en media.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A continuación se muestran las gráficas de densidades de los grados.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/avgdegree/degree-distribution.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/avgdegree/degree-distribution.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;En cuanto a grados totales, hay cuatro nodos que destacan, con un grado de mayor a 120. El nodo con mayor grado es de 161. Estos nodos se corresponden con &lt;em&gt;hubs&lt;/em&gt;. La distribución de grados indica que se cumple la propiedad libre de escala. Muy pocos con muchas conexiones, y muchos con pocas conexiones.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/avgdegree/indegree-distribution.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/avgdegree/indegree-distribution.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Los nodos con mayor grado de entrada (Con mayor número de seguidores) tienen 120 y 160 seguidores, respectivamente.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/avgdegree/outdegree-distribution.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/avgdegree/outdegree-distribution.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Pasa absolutamente lo mismo para los grados de entrada y salida, en el caso de Twitter esto indica seguidores y seguidos. El usuario con más amigos tiene unos 99 amigos.&lt;/p&gt;
&lt;h3 id=&#34;diámetro&#34;&gt;Diámetro&lt;/h3&gt;
&lt;p&gt;El diámetro de la red es de 13. Este valor representa la máxima distancia existente entre dos nodos en toda la red. La distancia media es de 4.5.&lt;/p&gt;
&lt;p&gt;El histograma de distancias es el siguiente:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/diameter/Closeness-Centrality-Distribution.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/diameter/Closeness-Centrality-Distribution.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;El diagrama de cercanía nos indica que hay bastantes nodos muy alejados del centro (entorno a unos 90). Otros, por contra, están muy situados en el centro de la red (unos 85). El resto de nodos se situan a los alrededores del centro de la red.&lt;/p&gt;
&lt;h3 id=&#34;conectividad&#34;&gt;Conectividad&lt;/h3&gt;
&lt;p&gt;Se tienen 845 componentes conexas, la componente gigante agrupa 1261 nodos. El coeficiente de clustering medio es 0.068. En este caso es bajo, ya que la cuenta de twitter es de un blog, en lugar de una cuenta personal. El histograma CC es el siguiente:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/gephi/clustering.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/gephi/clustering.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Lo cual indica que en regiones poco pobladas el coeficiente de clustering es muy alto, ya que los nodos están más conectados entre ellos localmente. Por ello destaca un punto muy alto al principio de la gráfica.&lt;/p&gt;
&lt;h2 id=&#34;centralidad-de-los-actores&#34;&gt;Centralidad de los actores&lt;/h2&gt;
&lt;p&gt;Los cinco primeros actores para las siguientes medidas son:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Centralidad de Grado&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Intermediación&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Cercanía&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Vector propio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;nixcraft: 161&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;rootjaeger: 0.048&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;programador4web: 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Makova_: 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Makova_: 151&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;podcastlinux: 0.048&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;KevinhoMorales: 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;psicobyte_: 0.966&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;cenatic: 132&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Linuxneitor: 0.043&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;elrne: 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Terceranexus6: 0.908&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Terceranexus6: 129&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Makova_: 0.039&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Mrcoo16: 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NuriaStatgirl: 0.796&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;LignuxSocial: 121&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Wdesarrollador: 0.038&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;RodriKing14: 1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Inter_ferencias: 0.780&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;En cuanto a la &lt;strong&gt;centralidad de grado&lt;/strong&gt;, no se tiene muy en cuenta, aunque refleja el número de conexiones de un actor, no tiene en cuenta la estructura global de la red.&lt;/p&gt;
&lt;p&gt;Una medida bastante importante es la &lt;strong&gt;intermediación&lt;/strong&gt;, estos actores hacen de puente entre otras regiones de la red. Por lo cual pueden conectar distintas comunidades entre sí. En el caso que nos ocupa (Twitter), si conseguimos que uno de estos actores nos mencione o nos haga RT, nuestro tweet podrá llegar a otro tipo de usuarios que quizá estén interesados en nuestras ideas.&lt;/p&gt;
&lt;p&gt;La &lt;strong&gt;cercanía&lt;/strong&gt; mide cómo de cerca está un actor del centro de la red. En este caso no nos sirve de mucho, ya que todos los nodos tienen la misma medida.&lt;/p&gt;
&lt;p&gt;Por último, la &lt;strong&gt;centralidad de vector propio&lt;/strong&gt; es una medida recursiva que asigna importancia a un nodo en función de la importancia de sus vecinos. Es decir, tiene en cuenta la calidad de las conexiones, en lugar de la cantidad. El primer actor tiene un valor de esta medida de 1, lo cual indica que es el nodo más importante y con el mayor número de conexiones importantes. Luego es un actor a tener en cuenta en la red.&lt;/p&gt;
&lt;h2 id=&#34;detección-de-comunidades&#34;&gt;Detección de comunidades&lt;/h2&gt;
&lt;p&gt;Para la detección de comunidades se ha usado un factor de resolución de 1.99 para obtener un total de 5 comunidades. Se ha elegido este valor de resolución debido a que valores inferiores resultaban en un mayor número de comunidades, pero muchas de ellas formadas por dos nodos. El valor para la modularidad es de un 0.436, lo cual es un buen valor.&lt;/p&gt;
&lt;p&gt;La proporción de nodos en cada comunidad es la siguiente:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;40.85%&lt;/li&gt;
&lt;li&gt;21.39%&lt;/li&gt;
&lt;li&gt;17.5%&lt;/li&gt;
&lt;li&gt;10.98%&lt;/li&gt;
&lt;li&gt;9.15%&lt;/li&gt;
&lt;li&gt;0.14%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La distribución de modularidad se observa en la siguiente imagen:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/mod/communities-size-distribution.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/mod/communities-size-distribution.png&#34; width=&#34;600&#34; height=&#34;400&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Todas tienen un tamaño razonable salvo una, demasiado pequeña.&lt;/p&gt;
&lt;p&gt;La siguiente imagen muestra el grafo coloreado en función de a qué comunidad
pertenece cada nodo:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/gephi/comunities.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/gephi/comunities.png&#34; width=&#34;768&#34; height=&#34;1116&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Analizando la red, se puede apreciar que la comunidad de arriba (Azul celeste) pertenece a nodos relacionados con la ETSIIT. Algunos miembros de esta comunidad hacen de puente (Son nodos con mucha intermediación) con otras comunidades. Por ejemplo, Makova_ y Linuxneitor hacen de puente con la comunidad morada, esta comunidad está más relacionada con usuarios de Linux y blogs de Linux. NataliaDiazRodrz hace de puente de la comunidad de la ETSIIT con la comunidad verde, más relacionada con la temática de Ciencia de Datos. Esto tiene sentido, ya que NataliaDiazRodrz estudió en la ETSIIT y trabaja en Ciencia de Datos, concretamente en temas de NLP. La comunidad Amarilla está relacionada con programación.&lt;/p&gt;
&lt;h2 id=&#34;gráficos-adicionales&#34;&gt;Gráficos adicionales&lt;/h2&gt;
&lt;p&gt;En la siguiente gráfica se muestra la red dispuesta con los colores en función del valor del vector propio, y el tamaño de los nodos como la intermediación:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/gephi/color-eige-size-betwenn.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/gephi/color-eige-size-betwenn.png&#34; width=&#34;538&#34; height=&#34;792&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;En la siguiente figura se muestra a la inversa, color la intermediación, tamaño el vector propio:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/gephi/color-betwenn-size-eigen.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/gephi/color-betwenn-size-eigen.png&#34; width=&#34;644&#34; height=&#34;760&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Considero que las medidas más importantes son el valor de vector propio y la
intermediación, la siguiente gráfica muestra cómo están relacionadas entre
ellas. A mayor valor para ambas mejor, más importante es el nodo:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://elbauldelprogramador.com/img/gephi/eigenvsbt.png&#34;&gt;&lt;figure&gt;
    &lt;img src=&#34;https://elbauldelprogramador.com/img/gephi/eigenvsbt.png&#34; width=&#34;1024&#34; height=&#34;570&#34;/&gt; 
&lt;/figure&gt;
&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
        <item>
            <title>Aprendizaje no Supervisado y Detección de Anomalías: Reglas de Asociación Avanzadas</title>
            <link>https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas-avanzadas/</link>
            <pubDate>Tue, 03 Apr 2018 12:50:58 +0200</pubDate>
            
            <guid>https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas-avanzadas/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;Este articulo forma parte de una serie de artículos sobre clustering, detección de anomalías y reglas de asociación. Originalmente forman parte de un trabajo para el &lt;strong&gt;Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores&lt;/strong&gt; de la Universidad de Granada en la asignatura &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt;. El resto de artículos son:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-clustering/&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-anomalias/&#34;&gt;Detección de Anomalias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas/&#34;&gt;Reglas de Asociación&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Uno de los problemas de las reglas de asociación es la interpretabilidad, estos pueden venir derivados de los datos en sí, de los usuarios o de las propias medidas de evaluación.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Los problemas derivados de los datos&lt;/strong&gt; residen en que hay varias formas de interpretar que si A \(\rightarrow\) B en función de las medidas de calidad usadas. Al ser patrones en los datos, la calidad de la regla dependerá de igual modo de la calidad de los datos. Algunos problemas derivados de &lt;strong&gt;los datos&lt;/strong&gt; son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;falta de variabilidad&lt;/strong&gt;, &lt;em&gt;items&lt;/em&gt; muy frecuentes no aportan nada (Todos los clientes compran papel) o al contrario, &lt;em&gt;items&lt;/em&gt; poco frecuentes tampoco aportan nada.&lt;/li&gt;
&lt;li&gt;La &lt;strong&gt;representabilidad&lt;/strong&gt; de los datos, es decir, que no haya suficientes datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sesgos muestrales&lt;/strong&gt;, es necesario escoger los &lt;em&gt;items&lt;/em&gt; de forma aleatoria, no sesgarlos seleccionado compras de un periodo determinado, como las compras de enero, por ejemplo.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Por otra parte, &lt;strong&gt;los problemas derivados del usuario&lt;/strong&gt; pueden deberse a que no se dispone de un experto en el dominio del problema para interpretar y valorar las reglas. Aún cuando se dispone de un experto, pueden ocasionarse &lt;strong&gt;confusiones semánticas&lt;/strong&gt; en las que se interpretan mal las reglas o los valores de confianza etc.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Los &lt;strong&gt;problemas derivados de las medidas&lt;/strong&gt;, las reglas con soportes muy altos tienden a ser dudosas, ya que su valor tan elevado puede deberse a una &lt;strong&gt;falta de variabilidad&lt;/strong&gt; en los datos. De igual modo, &lt;strong&gt;la confianza&lt;/strong&gt; no siempre es fiable, una regla con una confianza del 84% puede parece buena, pero aún teniendo una regla con máxima confianza (conf = 1) puede que los &lt;em&gt;items&lt;/em&gt; de A \(\rightarrow\) B sean independientes.&lt;/p&gt;
&lt;p&gt;Para tratar de resolver estos problemas es necesario poder comparar la confianza de la regla con el soporte de su consecuente, dada A \(\rightarrow\) B, \(p(B|A)\) la confianza, \(p(B)\) el soporte de B, es necesario comprar ambas medidas, ya que \(p(B)\) es la probabilidad a priori, mientras que \(p(B|A)\) es solo la probabilidad de las reglas en las que aparece A. Si la $Conf(A \(\rightarrow\) B) = Sop(B)$ A y B son independientes y la regla no es representativa. Aunque la confianza por sí sola no vale para determinar si una regla es buena, sí que vale para descartar una regla mala.&lt;/p&gt;
&lt;h1 id=&#34;medidas-de-calidada-idsec-4-1-namesec-4-1a&#34;&gt;Medidas de calidad&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Existen dos grupos de medidas de Interés, &lt;strong&gt;objetivas&lt;/strong&gt; y &lt;strong&gt;subjetivas&lt;/strong&gt;. Las primeras tienen fundamento estadístico, mientras que las subjetivas solo tienen en cuenta los datos.&lt;/p&gt;
&lt;p&gt;Entre las &lt;strong&gt;medidas objetivas&lt;/strong&gt; se encuentran &lt;strong&gt;La Confianza Confirmada&lt;/strong&gt;, establece hasta qué punto es útil A para predecir la presencia de B, la medida se da en un rango [-1, 1], donde 0 significa que son independientes, 1 dependencia total y -1 dependencia inversa (A predice ¬ B). &lt;strong&gt;Lift&lt;/strong&gt; mide el nivel de interés, pero al ser simétrica mide asociaciones, no implicaciones, por lo cual no es buena para realizar comparaciones. &lt;strong&gt;Convicción&lt;/strong&gt; detecta la independencia estadística entre &lt;em&gt;items&lt;/em&gt;, al igual que &lt;strong&gt;lift&lt;/strong&gt; no está acotada en su salida, por lo que no es muy fiable. El &lt;strong&gt;factor de certeza&lt;/strong&gt; mide la incertidumbre del conocimiento, tiene su origen en los &lt;strong&gt;sitemas expertos&lt;/strong&gt;, la ventaja frente a las dos medidas anteriores es que está acotada en rangos [-1,1], donde 0 significa independencia estadística. Existen más medidas, estas son solo unas pocas. Por lo general, el análisis de la regla depende de la medida a usar. Es necesario usar medidas en función de la semántica que se quiere medir.&lt;/p&gt;
&lt;p&gt;Las &lt;strong&gt;medidas subjetivas&lt;/strong&gt; miden el interés de las reglas, suele ser necesaria la presencia de un experto que valore el interés de las mismas. Una de ellas es la &lt;strong&gt;Utilidad&lt;/strong&gt;, en ella hay que tener en cuenta:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Restricciones&lt;/strong&gt;: ¿Qué condiciones o qué contexto es necesario para que el patrón se cumpla?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tiempo de vida&lt;/strong&gt;: ¿Durante cuánto tiempo será útil la información dada por el patrón?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Esfuerzo&lt;/strong&gt;: ¿Qué debemos hacer para actuar según nos muestre el patrón?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Efectos laterales&lt;/strong&gt;: ¿Se puede prever algún efecto lateral?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impacto&lt;/strong&gt;: Desde la obtención del patrón, ¿se han producido cambios en la actualidad?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Prontitud&lt;/strong&gt;: ¿Cuándo podemos actuar y utilizar la información que nos brinda el patrón?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Las &lt;strong&gt;reglas inesperadas&lt;/strong&gt; son otro tipo de medida subjetiva, son aquellas que contradicen las creencias del usuario, pueden ser interesantes o no.&lt;/p&gt;
&lt;h1 id=&#34;interpretacionesa-idsec-4-2-namesec-4-2a&#34;&gt;Interpretaciones&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Esta sección se corresponde con el &lt;strong&gt;marco formal&lt;/strong&gt; de las reglas de asociación, es decir, la definición teórica de las reglas, de forma abstracta. Para ello hay que asociar dicha abstracción con los datos, crear una asociación entre datos y reglas, es esto lo que genera una interpretación.&lt;/p&gt;
&lt;p&gt;La forma más común es tabular los datos en una estructura, por ejemplo (salario, alto) \(\rightarrow\) (estudios, superiores), pero no es la única manera de representación. Se puede, por ejemplo, considerar la ausencia de datos con negaciones (¬ A), esta representación es útil para el análisis de grupos de reglas.&lt;/p&gt;
&lt;p&gt;Otra forma de representación son las &lt;strong&gt;reglas jerárquicas&lt;/strong&gt;, en esta representación se consideran grupos de &lt;em&gt;items&lt;/em&gt; a distintos niveles. Por ejemplo, si los &lt;em&gt;items&lt;/em&gt; son artículos de compra, un análisis a nivel de artículos individuales puede no dar información alguna. Sin embargo, a un nivel más alto se puedan extraer conclusiones útiles, un nivel más alto consiste en agrupar los distintos artículos según algún criterio (por marcas, por tipo de producto, tipos de pan, tipos de leche etc). De esta forma se establece una jerarquía en la que un &lt;em&gt;item&lt;/em&gt; está compuesto por los &lt;em&gt;items&lt;/em&gt; básicos y todas las categorias a las que pertenece, por ejemplo:
$$\text{(zumo, naranja, marca, comida)}$$
donde  &lt;em&gt;marca&lt;/em&gt; y &lt;em&gt;comida&lt;/em&gt; son categorías del &lt;em&gt;zumo&lt;/em&gt;. En la figura &lt;!-- raw HTML omitted --&gt;1&lt;!-- raw HTML omitted --&gt; muestra un ejemplo.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Las &lt;strong&gt;reglas secuenciales&lt;/strong&gt; se usan cuando &lt;strong&gt;existe un orden&lt;/strong&gt; prefijado en los &lt;em&gt;items&lt;/em&gt; de las transacciones. Ejemplos de reglas de este tipo son, si A,B y C aparecen en este &lt;strong&gt;orden específico&lt;/strong&gt; \(\rightarrow\) X. Este tipo de reglas son útiles para analizar textos, ya que se extraen reglas como {Minería}{de} \(\rightarrow\) {Datos}, es decir, si se encuentra la palabra &lt;strong&gt;Minería&lt;/strong&gt; seguida de &lt;strong&gt;De&lt;/strong&gt; es muy probable que la siguiente palabra sea &lt;strong&gt;datos&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Otro tipo de reglas son las &lt;strong&gt;Cuantitativas&lt;/strong&gt;, usadas con datos estructurados, con dominios numéricos, el problema de estos dominios es su valor semántico y soporte bajo. Para ello, se comentó que es útil dividir el dominio en intervalos y generar  pares (atributo, intervalo) en lugar de (atributo, valor), estos &lt;em&gt;items&lt;/em&gt; deben estar ordenados. Los intervalos pueden se definidos por el experto para que puedan ser correctamente interpretados, o generarlos automáticamente.&lt;/p&gt;
&lt;p&gt;Las &lt;strong&gt;dependencias aproximadas&lt;/strong&gt;  definen patrones en  bases de datos relacionales, corresponden a dependencias funcionales con excepciones, es decir, si se sabe que V se encuentra en una fila se sabe que W está en la misma fila. En esta interpretación las reglas extraidas tienen la semántica de la dependencia funcional, es decir, los &lt;em&gt;items&lt;/em&gt; son del tipo: Igualdad de variables en un par de tuplas.&lt;/p&gt;
&lt;p&gt;La última interpretación son las &lt;strong&gt;dependencias graduales&lt;/strong&gt;, representan asociaciones entre la variación (incrementos o decrementos) en los valores de los atributos, representando así correlaciones positivas o negativas. Se puede comparar con las &lt;strong&gt;dependencias aproximadas&lt;/strong&gt; en cuanto a que esta en lugar de determinar si los valores son iguales, determina si son mayores o menores.&lt;/p&gt;
&lt;h1 id=&#34;reglas-de-asociación-difusasa-idsec-4-3-namesec-4-3a&#34;&gt;Reglas de Asociación difusas&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Se usan para representar conceptos, por ejemplo, ¿cuando  es una persona alta?, si consideramos 180cm como alto, ¿una persona que mida 179,99 ya no es alta?, este es el problema que tratan los &lt;strong&gt;conjuntos difusos&lt;/strong&gt;, la pertenencia o no de un elemento a un conjunto viene dada por un grado de certeza. La figura &lt;!-- raw HTML omitted --&gt;2&lt;!-- raw HTML omitted --&gt; muestra un ejemplo en el que se define el rango en el que aumenta si una persona es alta o no, pero presenta el problema comentado anteriormente. Otra forma de representarlo es mediante una función discontinua, como muestra la figura &lt;!-- raw HTML omitted --&gt;3&lt;!-- raw HTML omitted --&gt;, pero tampoco es ideal, lo mejor es una función gradual, como muestra la figura &lt;!-- raw HTML omitted --&gt;4&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Las reglas difusas aparecen solo cuando se consideran &lt;strong&gt;conjuntos difusos&lt;/strong&gt; para definir algún concepto con &lt;em&gt;items&lt;/em&gt;, transacciones etc, son conjuntos continuos. En este tipo de reglas el soporte depende mucho de dónde se establecen los cortes que definen los intervalos. &lt;strong&gt;Semánticamente&lt;/strong&gt; los intervalos no corresponden con el concepto (30 años es joven, pero 31 no). Para dar solución a este problema se usan conjuntos difusos con &lt;strong&gt;funciones de pertenencia&lt;/strong&gt;, como muestra la figura &lt;!-- raw HTML omitted --&gt;5&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;evaluación-de-reglas-por-gruposa-idsec-4-4-namesec-4-4a&#34;&gt;Evaluación de reglas por grupos&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;El análisis de las reglas de asociación suele realizarse de forma individual, estudiando su novedad y potencial utilidad en base a los itemsets que la componen, las medidas &lt;strong&gt;objetivas y subjetivas&lt;/strong&gt; realizadas sobre ellas, y el conocimiento previo del experto. Sin embargo, el análisis de conjuntos de reglas definidos según ciertos criterios puede proporcionar más información, con ciertas ventajas. Por ejemplo, ¿qué ocurre si aparecen ambas reglas A \(\rightarrow\) C y A \(\rightarrow\) ¬ C? o A \(\rightarrow\) C y ¬ C \(\rightarrow\) ¬ A (contra recíproca), la última es lógicamente equivalente. Sin embargo, la logica formal y el conocimento de datos no son lo mismo, al buscar reglas en un conjunto de datos se puede deducir A \(\rightarrow\) B, pero no se sabe nada sobre ¬ B \(\rightarrow\) A. El motivo es que ¬ B \(\rightarrow\) A no aparece en las transacciones, es decir, las transacciones de A \(\rightarrow\) B son distintas a ¬ B \(\rightarrow\) ¬ A, aunque sean lógicamente equivalentes, por ello es necesario mirarlas por separado. En el caso de que ambas aparezcan se proporciona más soporte empírico de que el patrón se cumple, lo cual ocurre siempre que existen reglas lógicamente equivalentes.&lt;/p&gt;
&lt;h1 id=&#34;bibliografía-a-idsec-5-namesec-5a&#34;&gt;Bibliografía &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2F04PCT&#34;&gt;Cap 8. Introduction to Data Mining 1st edition by Tan, Pang-Ning, Steinbach, Michael, Kumar, Vipin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2sYPCAl&#34;&gt;Data Mining, Southeast Asia Edition: Concepts and Techniques (The Morgan Kaufmann Series in Data Management Systems)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Minkowski_distance&#34;&gt;https://en.wikipedia.org/wiki/Minkowski_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;https://en.wikipedia.org/wiki/Euclidean_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Taxicab_geometry&#34;&gt;https://en.wikipedia.org/wiki/Taxicab_geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Chebyshev_distance&#34;&gt;https://en.wikipedia.org/wiki/Chebyshev_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apuntes de clase &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt; del &lt;strong&gt;Máster universitario en Ciencia de Datos e Ingeniería de Computadores de la Universidad de Granada&lt;/strong&gt;*&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>Aprendizaje no Supervisado y Detección de Anomalías: Reglas de Asociación</title>
            <link>https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas/</link>
            <pubDate>Wed, 21 Mar 2018 12:15:14 +0100</pubDate>
            
            <guid>https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;Este articulo forma parte de una serie de artículos sobre clustering, detección de anomalías y reglas de asociación. Originalmente forman parte de un trabajo para el &lt;strong&gt;Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores&lt;/strong&gt; de la Universidad de Granada en la asignatura &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt;. El resto de artículos son:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-clustering/&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-anomalias/&#34;&gt;Detección de Anomalias&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas-avanzadas/&#34;&gt;Reglas de Asociación Avanzadas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Las reglas de asociación se usan para aportar conocimiento que ayude a la toma de decisiones. Ejemplos en los que este tipo de métodos resulta útil es para conocer las tendencias de compra de los clientes. Otra aplicación es en tareas de predicción, como deducir los estudios de una persona en función de su salario. &lt;strong&gt;Minería de textos&lt;/strong&gt; para asociar la presencia de términos en documentos etc.&lt;/p&gt;
&lt;p&gt;Este tipo de modelos se usa cuando prima la interpretabilidad del modelo, y son modelos predictivos. Es habitual usarlo &lt;strong&gt;conjuntos difusos&lt;/strong&gt;. A diferencia de los árboles, que parten el espacio, las &lt;strong&gt;reglas cubren parte del espacio&lt;/strong&gt;, disponiendo de un grado de cubrimiento y un acierto. Disponer de un &lt;strong&gt;grado de cubrimiento&lt;/strong&gt; significa que las regiones de decisión pueden &lt;strong&gt;solaparse o dejar zonas sin cubrir&lt;/strong&gt;, de ahí que sean muy usadas en problemas difusos.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;definicióna-idsec-3-1-namesec-3-1a&#34;&gt;Definición&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Las reglas de asociación son una de las técnicas más usadas para extraer conocimiento a partir de bases de datos grandes. Identifican relaciones existentes entre los datos, llamados &lt;em&gt;items&lt;/em&gt;. Se trata de una técnica de &lt;strong&gt;aprendizaje no supervisado&lt;/strong&gt;. Una regla se define como \(X \rightarrow Y\), donde \(X\) e \(Y\) son conjuntos de &lt;em&gt;items&lt;/em&gt; disjuntos \(X\mathcal{\cap} Y = \emptyset\). Un ejemplo: \(\text{Pan} \rightarrow \text{Mantequilla}\) Cuando se compra pan, se compra mantequilla.&lt;/p&gt;
&lt;p&gt;En sus inicios, las reglas de asociación se aplicaron a datos de supermercados, ya que a estos les interesa saber qué productos suelen comprar los clientes, para ponerlos unos junto a otros y así reducir el tiempo de compra del cliente. En el caso de un supermercado, &lt;strong&gt;los artículos&lt;/strong&gt; son los &lt;em&gt;items&lt;/em&gt; y el conjunto de &lt;strong&gt;cestas de la compra&lt;/strong&gt; son las transacciones. Cada transacción es un subconjunto de &lt;em&gt;items&lt;/em&gt;, llamado &lt;em&gt;itemset&lt;/em&gt;. Por ejemplo Leche y pan \(\rightarrow\) mantequilla.&lt;/p&gt;
&lt;p&gt;Los pasos a seguir antes de aplicar reglas de asociación es determinar qué datos de la base da datos son los &lt;em&gt;items&lt;/em&gt; y cuales las &lt;strong&gt;transacciones&lt;/strong&gt;. Los &lt;em&gt;items&lt;/em&gt; son los elementos a asociar, &lt;em&gt;pan, mantequilla, aceite…&lt;/em&gt; mientras que las transacciones son particularidades de la relación entre &lt;em&gt;items&lt;/em&gt; (la lista de la compra concreta).&lt;/p&gt;
&lt;p&gt;Los &lt;em&gt;items&lt;/em&gt; pueden ser de varios tipos. Cuando cada registro es un listado de elementos, como en el caso de productos de la compra, no existen variables, un &lt;em&gt;item&lt;/em&gt; se corresponde con un producto. Cuando existen variables con rangos, el &lt;em&gt;item&lt;/em&gt; es un par (atributo, valor), por ejemplo una variable &lt;strong&gt;puesto&lt;/strong&gt;, con valores &lt;em&gt;estudiante, jefe, trabajador&lt;/em&gt; tendría como &lt;em&gt;items&lt;/em&gt; (Puesto, estudiante), (Puesto, jefe) y (puesto, trabajador). Ejemplos de reglas usando &lt;em&gt;items&lt;/em&gt; de este tipo son: (Salario, alto) \(\rightarrow\) (Estudios, Superiores). De la regla anterior se pueden deducir dos cosas: Todo el que tiene un salario alto tiene estudios superiores, o un salario alto implica estudios superiores.&lt;/p&gt;
&lt;h1 id=&#34;medidas-clásicas-soporte-y-confianzaa-idsec-3-2-namesec-3-2a&#34;&gt;Medidas Clásicas: Soporte y Confianza&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;El &lt;strong&gt;soporte&lt;/strong&gt; de un &lt;em&gt;itemset&lt;/em&gt; mide la frecuencia del &lt;em&gt;item&lt;/em&gt; o &lt;em&gt;itemset&lt;/em&gt; en la base de datos, es decir, la probabilidad de que el &lt;em&gt;itemset&lt;/em&gt; X esté en el conjunto de transacciones (\(p(X)\)). El &lt;strong&gt;soporte de una regla de asociación&lt;/strong&gt; (X \(\rightarrow\) Y ) es la frecuencia con la que ocurre el &lt;em&gt;itemset&lt;/em&gt; \(X \cup Y\). Es decir, la probabilidad de que el &lt;em&gt;itemset&lt;/em&gt; \(X \cup Y\) esté en el conjunto de transacciones (\(p(X\wedge Y)\)). La &lt;strong&gt;confianza&lt;/strong&gt; define cómo de fiable es la regla, es decir, cómo de seguro está el modelo de que cuando se da \(X\) va a ocurrir \(Y\). Es útil comprobar la confianza en ambos sentidos de la regla, es decir, dado X \(\rightarrow\) Y comprobar tanto \(Conf(X, Y)\), como \(Conf(Y, X)\). Como regla general, una confianza superior al 80% es buena, aunque esto es subjetivo y depende del problema y el experto.&lt;/p&gt;
&lt;p&gt;Definidas las medidas clásicas, la extracción de las reglas se lleva a cabo a partir de un conjunto de transacciones T. Dado ese conjunto se desea encontrar todas las reglas que cumplan:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;minSup&lt;/code&gt;: Definido como Soporte \(\geq\) soporte mínimo.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;minConf&lt;/code&gt;: Definida como Confianza \(\geq\) confianza mínima.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ambos valores los debe definir el experto del problema.&lt;/p&gt;
&lt;p&gt;Lo más sencillo es resolver este problema mediante fuerza bruta (Generar todas la reglas posibles, calcular para cada una de ellas el soporte y confianza y descartar las que no superen los umbrales anteriores). Sin embargo es inviable para problemas grandes. El enfoque basado en dos pasos &lt;strong&gt;genera primero todos los &lt;em&gt;itemset&lt;/em&gt; frecuentes&lt;/strong&gt; (aquellos con un soporte mayor o igual al umbral &lt;code&gt;minSup&lt;/code&gt;), posteriormente &lt;strong&gt;genera las reglas con una confianza alta&lt;/strong&gt; basándose en los &lt;em&gt;itemset&lt;/em&gt; anteriores. El problema de esta aproximación es que el número de combinaciones posibles es de \(2^d\), siendo \(d\) el número de &lt;em&gt;items&lt;/em&gt;, y por tanto la generación de los &lt;em&gt;itemset&lt;/em&gt; es costosa.&lt;/p&gt;
&lt;p&gt;Dado a la inviabilidad de resolver el problema mediante fuerza bruta, es necesario &lt;strong&gt;reducir el número de candidatos posibles&lt;/strong&gt; (de los \(2^d\) usar técnicas de poda para reducir el espacio), el &lt;strong&gt;número de transacciones&lt;/strong&gt; y el &lt;strong&gt;número de comparaciones&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id=&#34;métodos-clásicos-de-extracción-de-reglasa-idsec-3-3-namesec-3-3a&#34;&gt;Métodos Clásicos de extracción de reglas&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;h2 id=&#34;algoritmo-aprioria-idsec-3-3-1-namesec-3-3-1a&#34;&gt;Algoritmo Apriori&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;h2 id=&#34;definicióna-idsec-3-3-1-1-namesec-3-3-1-1a&#34;&gt;Definición&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;El primer método clásico se llama &lt;strong&gt;Apriori&lt;/strong&gt;, es el que peor funciona de todos, pero del que más versiones existen. Se basa en la propiedad de &lt;strong&gt;anti monotonía del soporte&lt;/strong&gt;, es decir, si un &lt;em&gt;itemset&lt;/em&gt; es frecuente, entonces todos sus subconjuntos deben serlo también:&lt;/p&gt;
&lt;p&gt;$$X\subseteq Y \Rightarrow sop(X) \geq sop(Y)$$&lt;/p&gt;
&lt;h2 id=&#34;algoritmoa-idsec-3-3-1-2-namesec-3-3-1-2a&#34;&gt;Algoritmo&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;El algoritmo funciona del siguiente modo:
En memoria mantiene dos tablas, \(L_k\) guarda el conjunto de &lt;em&gt;k-itemsets&lt;/em&gt; frecuentes, \(C_k\) almacena el conjunto de &lt;em&gt;k-itemsets&lt;/em&gt; candidatos a ser frecuentes. El algoritmo (Suponiendo &lt;code&gt;k=1&lt;/code&gt; ):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generar \(L_1\) (&lt;em&gt;itemsets&lt;/em&gt; frecuentes de longitud 1)&lt;/li&gt;
&lt;li&gt;Repetir hasta que no se encuentren más &lt;em&gt;itemsets&lt;/em&gt; nuevos:
&lt;ol&gt;
&lt;li&gt;Generar el conjunto C(k+1) de &lt;em&gt;itemsets&lt;/em&gt; candidatos a partir de \(L_k\), combinando solo aquellos que se diferencien en el último &lt;em&gt;item&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Calcular el soporte de cada candidato.&lt;/li&gt;
&lt;li&gt;Eliminar los candidatos infrecuentes.&lt;/li&gt;
&lt;li&gt;Incrementar k en 1.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;La &lt;!-- raw HTML omitted --&gt;figura 1&lt;!-- raw HTML omitted --&gt; muestra un ejemplo.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;eficienciaa-idsec-3-3-1-3-namesec-3-3-1-3a&#34;&gt;Eficiencia&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;La &lt;strong&gt;elección del umbral&lt;/strong&gt; para el soporte mínimo debe ser adecuada, umbrales demasiado bajos dan lugar a muchos &lt;em&gt;itemsets&lt;/em&gt; e incrementará la complejidad. El &lt;strong&gt;número de &lt;em&gt;items&lt;/em&gt; en la base da datos&lt;/strong&gt; es un factor importante y afecta al rendimiento del algoritmo. De igual manera, el &lt;strong&gt;tamaño de la base de datos&lt;/strong&gt; puede hacer incrementar considerablemente el tiempo de ejecución, ya que &lt;strong&gt;apriori&lt;/strong&gt; realiza múltiples pasadas a toda la base de datos. Por último, la &lt;strong&gt;longitud de las transacciones&lt;/strong&gt; puede aumentar la longitud de los &lt;em&gt;itemsets&lt;/em&gt; frecuentes, requiriendo de más espacio para almacenarlos.&lt;/p&gt;
&lt;h2 id=&#34;algoritmo-eclata-idsec-3-3-2-namesec-3-3-2a&#34;&gt;Algoritmo Eclat&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Este algoritmo es igual que &lt;strong&gt;Apriori&lt;/strong&gt; pero mejora el cálculo del soporte obteniendo el mismo resultado. Para cada &lt;em&gt;item&lt;/em&gt; almacena en una lista en qué transacción aparece dicho &lt;em&gt;item&lt;/em&gt;, de esta forma se reduce el tiempo de cómputo sacrificando más memoria.&lt;/p&gt;
&lt;h2 id=&#34;algoritmo-fp-growtha-idsec-3-3-3-namesec-3-3-3a&#34;&gt;Algoritmo FP-Growth&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;h2 id=&#34;definicióna-idsec-3-3-3-1-namesec-3-3-3-1a&#34;&gt;Definición&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Este algoritmo genera una representación comprimida de la base da datos mediante árboles. Mantiene una &lt;strong&gt;tabla cabecera&lt;/strong&gt; donde para cada &lt;em&gt;item&lt;/em&gt; hay una lista enlazando a todos los nodos del grafo en el cual aparece dicho &lt;em&gt;item&lt;/em&gt;. Además, el &lt;strong&gt;grafo de transacciones&lt;/strong&gt; resume las transacciones en la base de datos junto con el soporte del &lt;em&gt;itemset&lt;/em&gt; que se forma siguiendo el camino desde la raíz del grafo hasta el nodo en cuestión. Como &lt;strong&gt;requisito&lt;/strong&gt;, los &lt;em&gt;items&lt;/em&gt; deben estar ordenados. De todos los métodos vistos, &lt;strong&gt;FP-Growth&lt;/strong&gt; es el más eficiente.&lt;/p&gt;
&lt;h2 id=&#34;extracción-de-itemsets-frecuentesa-idsec-3-3-3-2-namesec-3-3-3-2a&#34;&gt;Extracción de &lt;em&gt;itemsets&lt;/em&gt; frecuentes&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;En este algoritmo se realiza en dos fases. Primero se calcula el soporte de los &lt;em&gt;items&lt;/em&gt; que aparecen en la &lt;strong&gt;tabla cabecera&lt;/strong&gt;, recorriendo la lista almacenada en la tabla. Posteriormente, para cada &lt;em&gt;item&lt;/em&gt; superando el umbral de soporte, se extraen las ramas del árbol donde aparece el &lt;em&gt;item&lt;/em&gt; y se reajusta el soporte de todos los &lt;em&gt;items&lt;/em&gt; que aparecen en las ramas. Se genera un nuevo árbol considerando las ramas extraidas y se extraen los &lt;em&gt;itemsets&lt;/em&gt; que superen el umbral de soporte mínimo.&lt;/p&gt;
&lt;h1 id=&#34;conjuntos-maximales-y-cerradosa-idsec-3-4-namesec-3-4a&#34;&gt;Conjuntos maximales y cerrados&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Los &lt;em&gt;itemsets Maximales&lt;/em&gt; son aquellos &lt;em&gt;itemsets&lt;/em&gt; frecuentes para los que ninguno de sus &lt;strong&gt;superconjuntos&lt;/strong&gt; inmediatos son frecuentes. La &lt;!-- raw HTML omitted --&gt;Figura 2&lt;!-- raw HTML omitted --&gt; muestra un ejemplo. Las ventajas de usar conjuntos maximales es la reducción del espacio, ya que a partir de los &lt;em&gt;itemsets&lt;/em&gt; frecuentes maximales se pueden deducir los &lt;em&gt;itemsets&lt;/em&gt; frecuentes. Como desventaja no se conoce el soporte de los &lt;em&gt;itemsets&lt;/em&gt; frecuentes, hay que volver a calcularlo.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Los &lt;em&gt;itemsets cerrados&lt;/em&gt; son los &lt;em&gt;itemsets&lt;/em&gt; frecuentes para los que ninguno de sus superconjuntos inmediatos tienen soporte igual al de ellos. Cabe destacar que todo &lt;em&gt;itemset maximal&lt;/em&gt; es también cerrado. La &lt;!-- raw HTML omitted --&gt;figura 3&lt;!-- raw HTML omitted --&gt; muestra un ejemplo. La ventaja de los &lt;em&gt;itemsets cerrados&lt;/em&gt; es que no es necesario volver a calcular el soporte, mientras que como desventaja necesitan más espacio, al haber más cerrados que maximales.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Para terminar, estos dos conjuntos están relacionados, como muestra la &lt;!-- raw HTML omitted --&gt;Figura 4&lt;!-- raw HTML omitted --&gt;, los maximales son un subconjunto de los cerrados.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;generación-de-reglasa-idsec-3-5-namesec-3-5a&#34;&gt;Generación de reglas&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;A partir de los &lt;em&gt;itemsets&lt;/em&gt; frecuentes se generan todas las reglas posibles y solo se quedan las que superen los umbrales de confianza mínimo. Por lo general es preferible general reglas con un solo elemento en el consecuente (ABC \(\rightarrow\) D), pero nada impide que exista más de un objeto en el consecuente, sin embargo, de este modo se generarán bastantes más reglas posibles. Como beneficio a generar reglas con un solo elemento en el consecuente se obtienen reglas más interpretables, ya que AB \(\rightarrow\) CD \(\equiv\) AB \(\rightarrow\) C y AB \(\rightarrow\) D.&lt;/p&gt;
&lt;h1 id=&#34;problemas-abiertosa-idsec-3-6-namesec-3-6a&#34;&gt;Problemas abiertos&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Todo el contenido anterior es para reglas de &lt;strong&gt;asociación binarias&lt;/strong&gt;, es decir, valores categóricos. Pero la mayoría de problemas reales contienen variables numéricas y las reglas no serán buenas. Para ello hay que dividir el domino de los atributos en intervalos, como se describió anteriormente (Puesto, Estudiante) etc y usar conjuntos difusos.&lt;/p&gt;
&lt;p&gt;En cuanto a las &lt;strong&gt;medidas de calidad&lt;/strong&gt; para evaluar reglas de asociación se debe tener cuidado. Por lo general se deben usar varias medidas de calidad que se complementen a la hora de evaluar la calidad de una regla, estas medidas, entre otras son &lt;em&gt;lift, factor de certeza…&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;consejosa-idsec-3-7-namesec-3-7a&#34;&gt;Consejos&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Si al generar reglas hay &lt;em&gt;items&lt;/em&gt; con soporte demasiado altos es mejor no tener en cuanta dichos &lt;em&gt;items&lt;/em&gt;. Por ejemplo, si un producto se compra el 100% de las veces, no merece la pena añadirlo a los &lt;em&gt;itemsets&lt;/em&gt;, ya que no va a aportar información útil.&lt;/li&gt;
&lt;li&gt;Antes de comenzar un problema de reglas de asociación, lo más importante es tener claro qué queremos encontrar en los datos y conocer el problema presente.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;bibliografía-a-idsec-5-namesec-5a&#34;&gt;Bibliografía &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2F04PCT&#34;&gt;Cap 8. Introduction to Data Mining 1st edition by Tan, Pang-Ning, Steinbach, Michael, Kumar, Vipin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2sYPCAl&#34;&gt;Data Mining, Southeast Asia Edition: Concepts and Techniques (The Morgan Kaufmann Series in Data Management Systems)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Minkowski_distance&#34;&gt;https://en.wikipedia.org/wiki/Minkowski_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;https://en.wikipedia.org/wiki/Euclidean_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Taxicab_geometry&#34;&gt;https://en.wikipedia.org/wiki/Taxicab_geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Chebyshev_distance&#34;&gt;https://en.wikipedia.org/wiki/Chebyshev_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apuntes de clase &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt; del &lt;strong&gt;Máster universitario en Ciencia de Datos e Ingeniería de Computadores de la Universidad de Granada&lt;/strong&gt;*&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>Aprendizaje no Supervisado y Detección de Anomalías: ¿Qué es una Anomalía?</title>
            <link>https://elbauldelprogramador.com/aprendizaje-nosupervisado-anomalias/</link>
            <pubDate>Mon, 12 Mar 2018 09:39:48 +0100</pubDate>
            
            <guid>https://elbauldelprogramador.com/aprendizaje-nosupervisado-anomalias/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;Este articulo forma parte de una serie de artículos sobre clustering, detección de anomalías y reglas de asociación. Originalmente forman parte de un trabajo para el &lt;strong&gt;Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores&lt;/strong&gt; de la Universidad de Granada en la asignatura &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt;. El resto de artículos son:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-clustering/&#34;&gt;Clustering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas/&#34;&gt;Reglas de Asociación&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas-avanzadas/&#34;&gt;Reglas de Asociación Avanzadas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Antes de comenzar es necesario definir qué es una &lt;strong&gt;anomalía&lt;/strong&gt;: Una anomalía es un dato muy distinto del resto. Esto puede deberse a fallos en mediciones, o a la propia naturaleza del dato. Por ejemplo, una intrusión a un sistema informático puede considerarse una anomalía, ya que por norma general el resto de actividades en dicho sistema serán legítimas. Por lo general, un dato se considera anómalo si escapa a los rangos de normalidad del resto de los datos.&lt;/p&gt;
&lt;p&gt;El tratamiento de los datos anómalos debe hacerse con cuidado, ya que en ocasiones se podrá descartar (cuando son errores de medición) y en otras será importante (Introsiones/ataques a un sistema).&lt;/p&gt;
&lt;p&gt;Ciertas técnicas de aprendizaje son más robustas frente a datos anómalos que otras. Un ejemplo de ello es la &lt;strong&gt;regresión lineal&lt;/strong&gt;, la presencia de un dato anómalo afectará en gran medida al resultado del modelo, ya que este dato anómalo &lt;em&gt;“tirará”&lt;/em&gt; de la línea de regresión hacia él. Como muestra la &lt;!-- raw HTML omitted --&gt;Figura 1&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;También ocurre en &lt;em&gt;clustering&lt;/em&gt;, ya que los datos anómalos desplazan los centroides hacia ellos (&lt;!-- raw HTML omitted --&gt;Figura 2&lt;!-- raw HTML omitted --&gt;).&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Una buena analogía en este campo es encontrar una aguja en un pajar. Esa sería la forma fácil de encontrar una anomalía, ya que al menos se sabe que hay que encontrar una aguja. Pero en muchas ocasiones no se sabe &lt;strong&gt;qué es lo que se debe encontrar.&lt;/strong&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;aplicacionesa-idsec-2-1-namesec-2-1a&#34;&gt;Aplicaciones&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Algunas aplicaciones son los &lt;strong&gt;Sistemas de detección de intrusiones en red&lt;/strong&gt; (&lt;em&gt;Network Intrusion Detection Systems [NIDS]&lt;/em&gt; ). Cuando se conoce el tipo de anomalía los NIDS son basados en firmas, pero también existen sin conocer previamente el tipo de anomalía a detectar. Este documento se centrará en la última, NIDS basados en detección de anomalías. Ejemplos de este tipo de sistemas son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Detectar intrusiones de red.&lt;/li&gt;
&lt;li&gt;Fraude en tarjetas de crédito.&lt;/li&gt;
&lt;li&gt;Detectar brotes de epidemias.&lt;/li&gt;
&lt;li&gt;Análisis de regiones sospechosas en imágenes (Como radiografías).&lt;/li&gt;
&lt;li&gt;Video vigilancia.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;métodos-supervisadosa-idsec-2-2-namesec-2-2a&#34;&gt;Métodos supervisados&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Cuando se conoce la existencia de anomalías en los datos, y se sabe cuales son, las técnicas usadas son de clasifiación supervisada. En este tipo de problemas se tienen dos conjuntos de datos, uno de entrenamiento y otro de test. Como se dispone de toda la información, los datos están etiquetados en función de si son anomalía o no. Con estos datos se construye un modelo que aprenda a distinguir ente un dato anómalo y uno legítimo.&lt;/p&gt;
&lt;p&gt;Una situación muy común en este tipo de datos es que están desbalanceados. Existen muchos más datos legítimos que anómalos, lo cual sesga el resultado del modelo. Este tipo de problemas se conoce como &lt;strong&gt;calsificación desbalanceada&lt;/strong&gt;. Principalmente existen dos métodos para lidiar con este problema. &lt;strong&gt;Métodos basados en Instancias&lt;/strong&gt; y &lt;strong&gt;basados en algoritmos.&lt;/strong&gt; El primero consiste en modificar los datos antes de pasarlos al algoritmo, mientras que el segundo usa los datos originales sobre un algoritmo modificado.&lt;/p&gt;
&lt;h2 id=&#34;basados-en-instanciasa-idsec-2-2-1-namesec-2-2-1a&#34;&gt;Basados en Instancias&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;La forma de modificar los datos antes de pasarlos al algoritmo consiste en eliminar instancias de la clase mayoritaria (&lt;em&gt;undersampling&lt;/em&gt;) o crear instancias artificiales de la clase minoritaria (&lt;em&gt;oversampling&lt;/em&gt;). Algunos métodos de &lt;em&gt;underasmpling&lt;/em&gt; son &lt;em&gt;Tomek-links, CNN y NCL&lt;/em&gt;, de &lt;em&gt;oversampling&lt;/em&gt; SMOTE, aunque este último realiza un &lt;em&gt;undersampling&lt;/em&gt; a la clase mayoritaria a la vez de un &lt;em&gt;oversampling&lt;/em&gt; de la clase minoritaria.&lt;/p&gt;
&lt;h2 id=&#34;basados-en-algoritmosa-idsec-2-2-2-namesec-2-2-2a&#34;&gt;Basados en Algoritmos&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;En este caso no se alteran los datos, pero asignan distintos pesos a cada instancia mediante una &lt;strong&gt;función de coste, bagging oo boosting&lt;/strong&gt;. Los métodos que usan la función de coste asignan costes muy altos a las clases minoritarias. &lt;strong&gt;Bagging&lt;/strong&gt; incluye más instancias de la clase minoritaria en cada paso del algoritmos de &lt;em&gt;bagging&lt;/em&gt;. Por contra, &lt;strong&gt;Boosting&lt;/strong&gt; asigna más peso a las instancias de la clase minoritaria en cada paso. También existen alternativas híbridas, como &lt;strong&gt;SmoteBoosting, SmoteBagging&lt;/strong&gt;  etc.&lt;/p&gt;
&lt;h2 id=&#34;métricas-de-evaluacióna-idsec-2-2-3-namesec-2-2-3a&#34;&gt;Métricas de evaluación&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;En este tipo de problemas la precisión del modelo no es importante, ya que un modelo sencillo que etiquete todas las instancias como legítimas podría tener un 99.9% de precisión en los casos en los que la anomalía esté presente el 0.1% del tiempo, y aún con este porcentaje de precisión no se estaría detectando ninguna anomalía. Esto es debido al desbalanceo entre las clases. Debido a ello es necesario usar otro tipo de métricas, como &lt;em&gt;Recall, Precisión, F-Measure, ROC etc&lt;/em&gt;.&lt;/p&gt;
&lt;h1 id=&#34;métodos-semi-supervisadosa-idsec-2-3-namesec-2-3a&#34;&gt;Métodos semi-supervisados&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Se conoce la existencia de anomalías, pero no se encuentran en el conjunto de datos. Con este conjunto de datos se define “*la normalidad*” del entorno. Por ejemplo, en datos de red, lo normal es que todo el tráfico sea legítimo, y sin saturaciones. El problema en esta situación es saber cómo modelar un “*comportamiento normal*”. Para ello hay varias técnicas, basadas en clasificación, en reglas de asociación, en máquinas de soporte vectorial.&lt;/p&gt;
&lt;p&gt;Los &lt;strong&gt;modelos de clasificación&lt;/strong&gt; en el caso de conjuntos de datos correctamente balanceados sufre de cometer demasiados falsos positivos. Cuando un nuevo dato llega al modelo de clasificación, y éste lo clasifica incorrectamente, el dato se considera como una anomalía, lo cual no tiene por qué ser cierto. Para mejorar este modelo, se suelen usar clasificadores basados en reglas. Los clasificadores basados en reglas proporcionan más información cuando un dato se clasifica incorrectamente, informan en qué grado se considera al dato  anómalo, por ejemplo, en un 80%. Otra forma de abordar el problema es mediante la generación de &lt;strong&gt;máquinas de estados finitos&lt;/strong&gt;, cuando llega un nuevo dato se comprueba contra esa máquina de estados finitos para determinar la legitimidad o no legitimidad. Un ejemplo de este tipo de modelos se encuentra en la &lt;!-- raw HTML omitted --&gt;Figura 3&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Los métodos &lt;strong&gt;basados en reglas&lt;/strong&gt; buscan patrones frecuentes y reglas de asociación. Uno de estos métodos es &lt;strong&gt;LERAD&lt;/strong&gt;. &lt;strong&gt;LERAD&lt;/strong&gt; aprende reglas que encuentran eventos extraños en una serie temporal.&lt;/p&gt;
&lt;p&gt;Los métodos basados en &lt;strong&gt;kernel&lt;/strong&gt; como Máquinas de Soporte Vectoriales asumen la existencia de una única clase definida como comportamiento normal. Este comportamiento normal se construye estableciendo una región en el espacio. Todo punto que caiga en ese espacio será considerado normal. Por contra, cuando un punto cae fuera de la región es considerado anómalo. Un ejemplo de la definición de este espacio se muestra en la &lt;!-- raw HTML omitted --&gt;Figura 4&lt;!-- raw HTML omitted --&gt;. Gracias a la potencia de los &lt;strong&gt;kernels&lt;/strong&gt; es posible definir distintos tipos de regiones en el espacio para realizar la detección.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Es posible construir modelos basándose en &lt;strong&gt;los datos históricos&lt;/strong&gt;. En este tipo de métodos se asume como anomalía cualquier evento que no se haya producido en el pasado. Para ello se lleva un recuento de los eventos ocurridos y se comparan con los datos históricos para intentar detectar anomalías.&lt;/p&gt;
&lt;h1 id=&#34;métodos-no-supervisadosa-idsec-2-4-namesec-2-4a&#34;&gt;Métodos no supervisados&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;Se dispone de anomalías en el conjunto, pero no están etiquetadas, no se conoce a priori si un dato es una anomalía o no, es decir, tanto anomalías como comportamientos legítimos están mezclados. En este campo existen también varias alternativas, las cuales se pasan a describir a continuación.&lt;/p&gt;
&lt;h2 id=&#34;aproximaciones-gráficasa-idsec-2-4-1-namesec-2-4-1a&#34;&gt;Aproximaciones gráficas&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Como su nombre indica consiste en inspeccionar visualmente los datos para determinar cuales son los datos anómalos. Su principal desventaja es la cantidad de tiempo a invertir, y que es subjetivo. Para poder usar esta aproximación es necesario reducir/resumir la información a una dimensión que pueda ser visualizada (1D, 2D o 3D), y por tanto se está perdiendo información que puede resultar relevante. Una de las aproximaciones visuales más útiles es el &lt;em&gt;biplot&lt;/em&gt;, que muestra una proyección a dos dimensiones de la varianza que aporta cada atributo. La &lt;!-- raw HTML omitted --&gt;figura 5&lt;!-- raw HTML omitted --&gt; muestra un &lt;em&gt;biplot&lt;/em&gt;, la longitud de los vectores para cada atributo muestra la dirección más fuerte de los datos. Si dos atributos son ortogonales significa que no están correlados, lo cual implica que ambos pueden usarse en la construcción del modelo para obtener mejores resultados. Por contra, si dos atributos van en la misma dirección y tienen similares longitudes, están correlados, o negativamente correlados si van en direcciones opuestas.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;aproximaciones-paramétricasa-idsec-2-4-2-namesec-2-4-2a&#34;&gt;Aproximaciones paramétricas&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Estas aproximaciones asumen un modelo paramétrico describiendo la distribución de los datos y usan tests estadísticos para determinar si un punto es  un &lt;em&gt;outlier&lt;/em&gt; con un nivel de significancia. Dichos tests dependen de la distribución inherente, sus parámetros y número de &lt;em&gt;outliers&lt;/em&gt; esperados. Entre los tests que consideran una sola variable se encuentran el &lt;strong&gt;test de Grubb&lt;/strong&gt;, que considera un solo &lt;em&gt;outlier&lt;/em&gt;, este test sufre de enmascaramiento (la media puede enmascarar &lt;em&gt;outliers&lt;/em&gt;) , los tests de &lt;strong&gt;Tietjen y Moore&lt;/strong&gt; consideran k &lt;em&gt;outliers&lt;/em&gt; y sufren de &lt;em&gt;swamping&lt;/em&gt; (de forma similar, la media oculta &lt;em&gt;outliers&lt;/em&gt;). Cuando hay varias dimensiones (p dimensiones) se considera la &lt;strong&gt;distancia de Mahalanobis&lt;/strong&gt;. En p dimensiones, un punto que sea considerado &lt;em&gt;outlier&lt;/em&gt; en uno de sus atributos seguirá siéndolo aunque en cualquiera de sus atributos restantes no sea considerado &lt;em&gt;outlier&lt;/em&gt;, o cuando sea &lt;em&gt;outlier&lt;/em&gt; en varios de sus atributos.&lt;/p&gt;
&lt;p&gt;El problema de los tests del párrafo anterior es que necesitan de una medida de distancia multivariante. Además, para poder calcular una matriz de covarianza de forma correcta es necesario eliminar los &lt;em&gt;outliers&lt;/em&gt;, de lo contrario la matriz no será correcta y proporcionará información falsa.&lt;/p&gt;
&lt;h2 id=&#34;aproximaciones-basadas-en-vecinos-cercanosa-idsec-2-4-3-namesec-2-4-3a&#34;&gt;Aproximaciones basadas en vecinos cercanos&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Las aproximaciones anteriores asumen una distribución normal de los datos, pero en muchos casos la distribución no es normal, e incluso se desconoce. Si se añade el hecho de dimensiones muy altas, los datos no suelen seguir una distribución multivariante específica. Aquí hay dos formas de obtener los vecinos, mediante una &lt;strong&gt;función de distancia&lt;/strong&gt; que mide la cercanía entre dos puntos o asignando una puntuación de anomalía a un punto en función de su distancia frente al resto de puntos vecinos.&lt;/p&gt;
&lt;h2 id=&#34;aproximaciones-basadas-en-clusteringa-idsec-2-4-4-namesec-2-4-4a&#34;&gt;Aproximaciones basadas en &lt;em&gt;clustering&lt;/em&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;En esta aproximación primero se construyen los &lt;em&gt;cluster&lt;/em&gt; mediante cualquier técnica de &lt;em&gt;clustering&lt;/em&gt;, posteriormente se mide la distancia de un punto a su centroide para determinar si se trata de una anomalía. Se debe elegir con cuidado la medida de distancia. La &lt;strong&gt;distancia Euclídea&lt;/strong&gt; no tiene en cuenta la densidad, por tanto es aconsejable usar la &lt;strong&gt;distancia relativa&lt;/strong&gt; (La distancia relativa es la relación entre la distancia del punto del centroide a la distancia mediana de todos los puntos del &lt;em&gt;cluster&lt;/em&gt;  desde el centroide).&lt;/p&gt;
&lt;h1 id=&#34;evaluacióna-idsec-2-5-namesec-2-5a&#34;&gt;Evaluación&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;En detección de anomalías no basta obtener simplemente el porcentaje de acierto, es necesaria una matriz de confusión en la que se pueda observar la tasa de &lt;strong&gt;falsos positivos&lt;/strong&gt; y &lt;strong&gt;falsos negativos&lt;/strong&gt;. Dado que lo importante en este tipo de problema es detectar la anomalía es necesario observar el comportamiento de la precisión para detectar la anomalía. Para ello se usa la fórmula \(\frac{TP}{TP + FP}\), que indica qué porcentaje en la predicción de anomalías es correcto, siendo TP un acierto verdadero y FP un falso positivo, a más cercana de 1 esta medida mejor. Es interesante fijarse en el &lt;em&gt;Recall&lt;/em&gt; (\(\frac{TP}{TP + FN}\)) que mide el porcentaje de anomalías detectadas, ya sean bien clasificadas o no. La proporción de falsos positivos \(\frac{FP}{FP + TN}\) mide el porcentaje de clases normales que fueron clasificadas como anomalías. Por último, la especifidad (\(\frac{TN}{TN + FP}\)) indica el porcentaje de clases normales detectadas. No es posible mejorar todas las medidas anteriores simultáneamente (Cuando aumente la precisión, el &lt;em&gt;Recall&lt;/em&gt; va a decaer, ya que son inversos). Para atajar este problema se usa la medida \(F_1\) -Score, la cual intenta encontar un equilibrio entre &lt;em&gt;Recall&lt;/em&gt; y precisión. Para terminar de aclarar estos conceptos, obtener una fiabilidad del \(99%\) en una enfermedad que ocurren en una de cada \(10000\) no es fiable, ya que se equivocará una vez de cada \(1000\). Cuando se habla de anomalías que aparecen muy poco el modelo va a cometer muchos falsos positivos, la solución a este problema es usar información adicional como la &lt;strong&gt;probabilidad a priori de la anomalía, porcentaje de acierto y tasa de falsos positivos.&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;bibliografía-a-idsec-5-namesec-5a&#34;&gt;Bibliografía &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2F04PCT&#34;&gt;Cap 8. Introduction to Data Mining 1st edition by Tan, Pang-Ning, Steinbach, Michael, Kumar, Vipin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2sYPCAl&#34;&gt;Data Mining, Southeast Asia Edition: Concepts and Techniques (The Morgan Kaufmann Series in Data Management Systems)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Minkowski_distance&#34;&gt;https://en.wikipedia.org/wiki/Minkowski_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;https://en.wikipedia.org/wiki/Euclidean_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Taxicab_geometry&#34;&gt;https://en.wikipedia.org/wiki/Taxicab_geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Chebyshev_distance&#34;&gt;https://en.wikipedia.org/wiki/Chebyshev_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apuntes de clase &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt; del &lt;strong&gt;Máster universitario en Ciencia de Datos e Ingeniería de Computadores de la Universidad de Granada&lt;/strong&gt;*&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>Aprendizaje no Supervisado y Detección de Anomalías: ¿Qué es el Clustering?</title>
            <link>https://elbauldelprogramador.com/aprendizaje-nosupervisado-clustering/</link>
            <pubDate>Mon, 05 Mar 2018 10:56:17 +0100</pubDate>
            
            <guid>https://elbauldelprogramador.com/aprendizaje-nosupervisado-clustering/</guid>
            <description>&lt;blockquote&gt;
&lt;p&gt;Este articulo forma parte de una serie de artículos sobre clustering, detección de anomalías y reglas de asociación. Originalmente forman parte de un trabajo para el &lt;strong&gt;Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores&lt;/strong&gt; de la Universidad de Granada en la asignatura &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt;. El resto de artículos son:&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-anomalias/&#34;&gt;Detección de anomalías&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas/&#34;&gt;Reglas de Asociación&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://elbauldelprogramador.com/aprendizaje-nosupervisado-reglas-avanzadas/&#34;&gt;Reglas de Asociación Avanzadas&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;El aprendizaje automático se distingue en dos tipos. &lt;strong&gt;Supervisado&lt;/strong&gt;, donde se dispone de información sobre la clase a la que pertenece una instancia o &lt;strong&gt;no supervisado&lt;/strong&gt;, donde esta información no está disponible. Estos apuntes se centran en el último tipo. En la figura se muestra un árbol de tipos de clasificaciones.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;clusteringa-idsec-1-namesec-1a&#34;&gt;Clustering&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;p&gt;&lt;em&gt;Clustering&lt;/em&gt; intenta encontrar patrones en los datos que formen grupos claramente separados. Encontrar estos grupos tiene varias aplicaciones. Por ejemplo si los datos tratan sobre clientes, cada grupo encontrado podría usarse para realizar una segmentación de clientes en marketing, y ofrecer así distintos productos a cada grupo. Otra posible aplicación es agrupar documentos por temática, donde cada &lt;em&gt;cluster&lt;/em&gt; o grupo pertenece a un tipo de documento. En este tipo de aplicaciones &lt;em&gt;clustering&lt;/em&gt; se usa como aplicación final, sin embargo puede usarse como paso previo a otras técnicas de aprendizaje. Algunos ejemplos son exploración de datos y preprocesamiento de datos.&lt;/p&gt;
&lt;p&gt;Uno de los problemas del &lt;em&gt;clustering&lt;/em&gt; es su subjetividad. En la Figura de abajo aparece un conjunto de datos, pero bajo este mismo conjunto se pueden hacer agrupamientos diferentes.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;medidas-de-similituda-idsec-1-1-namesec-1-1a&#34;&gt;Medidas de similitud&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Una solución al problema descrito en la sección anterior es definir una buena medida de similitud. Para ello es necesario usar únicamente los atributos adecuados, no es necesario usar todos los atributos para calcular la similitud de una instancia frente a otra. También es importante tener en cuenta las magnitudes de cada atributo como paso previo a calcular la similitud, y por tanto es necesario normalizar. Principalmente hay dos formas de normalizar un conjunto de datos para atributos continuos. El método &lt;em&gt;Min-Max&lt;/em&gt; y &lt;em&gt;z-score&lt;/em&gt;. Estas normalizaciones se deben llevar a cabo para cada atributo del conjunto de datos. Es recomendable eliminar cualquier &lt;strong&gt;outlier&lt;/strong&gt;, ya que puede afectar mucho al proceso de normalización. De los dos anteriores, es recomendable usar &lt;em&gt;z-score&lt;/em&gt;, ya que preserva el rango de los datos.&lt;/p&gt;
&lt;p&gt;Para crear medidas de similitud se consideran la semejanzas o distancias. A mayor valor de semejanza, más se parecen los dos puntos en comparación, sin embargo, a mayor distancia, menor parecido. Es común usar medidas de distancia para descubrir cómo de semejantes son dos puntos. Toda medida de distancia debe cumplir una serie de propiedades, listadas a continuación.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;No negativa: \(d(x,y) \geq 0\)&lt;/li&gt;
&lt;li&gt;Reflexiva: \(d(x,y) = 0\text{ sii } x = y\)&lt;/li&gt;
&lt;li&gt;Simétrica: \(d(x,y) = d(y,x)\)&lt;/li&gt;
&lt;li&gt;Desigualdad triangular: \(d(x,y) \leq d(x,z) + d(z,y)\)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La desigualdad triangular puede comprenderse mejor visualmente en la figura. Es decir, la suma de dos de los lados del triángulo siempre va a ser mayor o igual a la del lado restante. Como muestra la figura, conforme menos área tiene el triángulo, más cercana es la suma de dos lados al lado restante.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h3 id=&#34;medidas-de-distanciaa-idsec-1-1-1-namesec-1-1-1a&#34;&gt;Medidas de distancia&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;Las principales medidas de distancia son:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Euclídea&lt;/em&gt; o \(L_2 \) : \(d_2 (x,y) = \sqrt{\sum_{j=1}^J(x_j - y_j)^2}\)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Manhattan&lt;/em&gt; o \(L_1\): \(d_1 (x,y) = \sum_{j=1}^J|x_j - y_j|\)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Chebyshev&lt;/em&gt; o \(L_{\infty}\): \(d_\infty = \text{máx}_{j\dots J}|x_j - y_j|\)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Minkowski&lt;/em&gt; o Lr-norm: \(d_p(x,y) = \left ( \sum_{j=1}^J|x_j - y_j|^p\right )^\frac{1}{p}, p \geq 1\)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;La distancia Euclídea es la línea recta entre dos puntos. En la distancia Manhattan la distancia entre dos puntos es la suma en valor absoluto de las diferencias de sus coordenadas cartesianas. La Figura muestra cómo pueden existir varios caminos a dos puntos usando Manhattan, pero solo uno y el más corto por Euclídea.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;La distancia de Minkowski es una generalización de las dos anteriores&lt;/p&gt;
&lt;p&gt;En la distancia de Chebyshev la distancia entre dos puntos es la mayor de sus diferencias a lo largo de cualquiera de sus dimensiones coordenadas. También conocida como la distancia del tablero de ajedrez, por coincidir con el número de movimientos que puede hacer el rey para moverse por el tablero, como muestra la figura.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Por último la distancia de Minkowski es una generalización de las anteriores. Cuando \(p = 1\) corresponde con la distancia de Manhattan, para \(p = 2\) distancia Euclídea, y cuando \(p \to \infty\) corresponde con la distancia de Chebyshev. En la figura aparecen distintas distancias para varios valores de \(p\), en esta imagen se aprecia la distancia Manhattan para \(p=1\), Euclídea para \(p=2\) y Chebyshev para \(p=\infty\).&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;tipos-de-clusteringa-idsec-1-2-namesec-1-2a&#34;&gt;Tipos de Clustering&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Dentro de la clasificación no supervisada se distinguen principalmente los siguientes tipos de &lt;em&gt;clustering&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Agrupamiento por particiones&lt;/strong&gt;: Una simple división del conjunto de datos en sub conjuntos disjuntos (No solapados) de tal forma que cada punto del conjunto pertenece a uno de dichos subconjuntos (o &lt;em&gt;clusters&lt;/em&gt;). La figura es un ejemplo de este tipo de agrupamiento.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Basados en densidad&lt;/strong&gt;: En este tipo de &lt;em&gt;clustering&lt;/em&gt; un &lt;em&gt;cluster&lt;/em&gt; es una región densa de objetos rodeados por una región de baja densidad. Suele usarse cuando hay ruido y &lt;em&gt;outliers&lt;/em&gt; presentes en los datos.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Basados en Grafos&lt;/strong&gt;: Los datos se representan como un gráfo, los nodos son los puntos y los enlaces representan una conexión entre ambos. Un grupo de objetos conectados los unos con los otros pero no conectados con el resto de puntos en el conjunto de datos forma un &lt;em&gt;cluster&lt;/em&gt;. Para definir los grupos es necesario que cada objeto de un &lt;em&gt;cluster&lt;/em&gt; esté más cerca de cualquier otro punto de su grupo que a un punto de otro &lt;em&gt;cluster&lt;/em&gt;. Esta técnica tiene problemas en presencia de ruido u &lt;em&gt;outliers&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mínimo error cuadrático&lt;/strong&gt;: En este algoritmo se usa la minimización del error cuadrático para determinar a qué &lt;em&gt;cluster&lt;/em&gt; pertenece el punto. Esta técnica la usa el algoritmo K-Medias.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Jerárquico&lt;/strong&gt;: Si en el agrupamiento por particiones se permite que cada &lt;em&gt;cluster&lt;/em&gt; tenga sub-clusters se obtiene un &lt;em&gt;clustering&lt;/em&gt; jerárquico. Consiste en permitir que los &lt;em&gt;clusters&lt;/em&gt; puedan anidarse, organizado en forma de árbol. Cada nodo del árbol, un &lt;em&gt;cluster&lt;/em&gt; en este caso a exepción de los nodos hoja, forman la unión de sus hijos (los &lt;em&gt;sub-clusters&lt;/em&gt;). La raíz del árbol es el &lt;em&gt;cluster&lt;/em&gt; conteniendo a todos los datos. Los nodos hoja suelen corresponder con un único dato, pero no es obligatorio. La figura muestra un ejemplo de este tipo de &lt;em&gt;clustering&lt;/em&gt;. La figura (d) es un ejemplo de &lt;em&gt;clustering&lt;/em&gt; jerárquico, el nodo raíz contendría todos los puntos, el nodo a la izquierda está formado por un &lt;em&gt;cluster&lt;/em&gt; de tres &lt;em&gt;sub-clusters&lt;/em&gt;. Los métodos jerárquicos se clasifican en &lt;strong&gt;aglomerativos&lt;/strong&gt; o &lt;strong&gt;divisivos&lt;/strong&gt;. El primero considera cada punto un &lt;em&gt;cluster&lt;/em&gt; y en cada paso fusiona los pares más cercanos como un &lt;em&gt;cluster&lt;/em&gt;. Esta técnica requiere de una forma de medir la proximidad entre dos &lt;em&gt;clusters&lt;/em&gt;. El segundo comienza con todos los datos como un solo &lt;em&gt;cluster&lt;/em&gt; y subdivide hasta quedarse con puntos individuales como &lt;em&gt;clusters&lt;/em&gt;. Las técnicas aglomerativas son las más usadas, por esta razón se explican a continuación los distintos métodos. La figura los ilustra.
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Enlace Simple&lt;/strong&gt;: La proximidad entre dos &lt;em&gt;clusters&lt;/em&gt; viene dada por la distancia entre los dos puntos más cercanos de cada &lt;em&gt;cluster&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enlace Completo&lt;/strong&gt;: Análogo al anterior, pero usa la distancia de los dos puntos más lejanos de cada &lt;em&gt;cluster.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Enlace Ponderado&lt;/strong&gt;: Usa las distancias pares a pares de todos los puntos en cada &lt;em&gt;cluster&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Método de Ward&lt;/strong&gt;: Mide la proximidad entre dos &lt;em&gt;clusters&lt;/em&gt; usando el incremento del error cuadrático medio producido al unir dos &lt;em&gt;clusters&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;algoritmos-de-clusteringa-idsec-1-3-namesec-1-3a&#34;&gt;Algoritmos de &lt;em&gt;clustering&lt;/em&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;h3 id=&#34;k-meansa-idsec-1-3-1-namesec-1-3-1a&#34;&gt;K-Means&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;K-Means es un un algoritmo de &lt;em&gt;clustering&lt;/em&gt; por particiones. Tiene un parámetro de entrada, &lt;code&gt;k&lt;/code&gt;, indicando el número de &lt;em&gt;clusters&lt;/em&gt; a generar, por tanto es necesario conocer a priori el número de grupos a encontrar. Cada &lt;em&gt;cluster&lt;/em&gt; está representado por su centroide (centro geométrico del &lt;em&gt;cluster&lt;/em&gt;). Los centroides pueden ser puntos reales o no, en caso de ser un punto real del conjunto de datos se denominan menoides.  En cada iteración del algoritmo dichos centroides se recalculan hasta llegar a un criterio de parada. La figura muestra ejemplos de varias iteraciones de K-Means, en él se ilustra el proceso de actualización de los centroides.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;descripción-del-algoritmoa-idsec-1-3-1-1-namesec-1-3-1-1a&#34;&gt;&lt;strong&gt;Descripción del algoritmo&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;K-Means se compone de dos fases principales:&lt;/p&gt;
&lt;p&gt;El proceso de inicialización consta de dos pasos. Primeramente se escoge el número de centroides (k) y se asignan aleatoriamente, como muestra la figura (a). Una vez colocados los a cada punto se le asigna su correspondiente &lt;em&gt;cluster&lt;/em&gt; usando la media como medida de proximidad. Posteriormente se  recalculan los centroides con los puntos asignados y se actualizan.&lt;/p&gt;
&lt;p&gt;El proceso iterativo actualiza los centroides en cada iteración mientras los centroides cambien. En cada iteración se calcula la distancia de todos los puntos a los k centroides, formando k grupos y asignando a cada punto su centroide más cercano.&lt;/p&gt;
&lt;h4 id=&#34;asignación-de-clusters-a-los-puntosa-idsec-1-3-1-2-namesec-1-3-1-2a&#34;&gt;&lt;strong&gt;Asignación de clusters a los puntos&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Para asignar a un punto el &lt;em&gt;cluster&lt;/em&gt; más cercano es necesario usar una medida de proximidad, la más común es la distancia Euclídea (\(L_2\)), aunque no es la única y la elección depende del tipo de datos. Al re-calcular los centroides de cada &lt;em&gt;cluster&lt;/em&gt; se optimiza una &lt;strong&gt;función objetivo&lt;/strong&gt;, por ejemplo minimizar la distancias al cuadrado de cada punto a su &lt;em&gt;cluster&lt;/em&gt; más cercano, como muestra la siguiente ecuación:
\[SSE = \sum^K_{i=1}\sum_{\textbf{x}\in C_i} dist \left ( c_i, x \right )^2\]
donde \(C_i\) es el i-ésimo &lt;em&gt;cluster&lt;/em&gt;, \(c_i\) es el centróide del &lt;em&gt;cluster&lt;/em&gt; \(C_i\) y \(\textbf{x}\) es un punto y \(dist\) es la distancia.&lt;/p&gt;
&lt;p&gt;Con esta función objetivo, se calcula el error de cada punto, es decir, su distancia euclídea al &lt;em&gt;cluster&lt;/em&gt; más cercano, luego se calcula la suma total de los errores al cuadrado. Con este dato, y dados dos conjuntos de &lt;em&gt;clusters&lt;/em&gt; distintos generados por el algoritmo, K-Means escoge aquel con menor error cuadrático.&lt;/p&gt;
&lt;p&gt;Dada esta función objetivo, lo ideal es resolver el problema de optimización y encontrar el óptimo global, sin embargo es computacionalmente imposible de realizar. Por ello se realizan aproximaciones, como &lt;strong&gt;gradiente descendente&lt;/strong&gt;. Esta técnica consiste en escoger una solución inicial y repetir estos dos pasos: Calcular el cambio en la solución que mejor optimizar la función objetivo (Mediante derivadas) y actualizar la solución.&lt;/p&gt;
&lt;h4 id=&#34;elección-de-los-centroides-inicialesa-idsec-1-3-1-3-namesec-1-3-1-3a&#34;&gt;&lt;strong&gt;Elección de los centroides iniciales&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Elegir los centroides iniciales al azar usualmente no da buenos resultados, ya que el SSE variará notablemente en función de qué centroides iniciales se escojan. Una posible solución consiste en lanzar el algoritmo varias veces con distintos centroides iniciales y escoger los mejores, pero el problema sigue existiendo debido a la naturaleza aleatoria de este proceso. Otra alternativa es estimar seleccionar el primero punto de forma aleatoria, o calcular el centroide usando todos los puntos. Posteriormente, para cada centroide inicial, seleccionar el punto más alejado de cualquiera de los centroides iniciales ya seleccionados. De esta forma está garantizado elegir un conjunto de centroides iniciales aleatorios y separados entre sí.&lt;/p&gt;
&lt;h4 id=&#34;elección-del-k-óptimoa-idsec-1-3-1-4-namesec-1-3-1-4a&#34;&gt;&lt;strong&gt;Elección del k óptimo&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;No hay ninguna forma de obtener el &lt;code&gt;k&lt;/code&gt; óptimo salvo prueba y error. Sin embargo, se pueden usar algunas técnicas que suelen dar buenos resultados. Un ejemplo de ello es la técnica del codo. Se lanza el algoritmo para varios &lt;code&gt;k&lt;/code&gt; y se genera un gráfico de cada &lt;code&gt;k&lt;/code&gt; junto a su error. Un buen &lt;code&gt;k&lt;/code&gt; debería ser el que se corresponda con un &lt;a href=&#34;https://elbauldelprogramador.com/mostar-articulos-relacionados-blog/&#34; title=&#34;Mostrar artículos similares usando Clustering con sklearn&#34;&gt;codo&lt;/a&gt; en el gráfico. La figura muestra un ejemplo.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;problemas-de-k-meansa-idsec-1-3-1-5-namesec-1-3-1-5a&#34;&gt;&lt;strong&gt;Problemas de K-Means&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Los principales problemas de este algoritmo son los &lt;em&gt;outliers&lt;/em&gt;, ya que alteran las media de la distancia bastante. Una posible solución es usar la mediana como medida de proximidad en lugar de la media, en dicho caso es necesario usar la distancia de Manhattan. Una posible solución es eliminar dichos &lt;em&gt;outliers&lt;/em&gt;, pero dependiendo del tipo de datos esto puede ser otro problema en sí mismo. Otra forma es usar menoides en lugar de centroides. Al usar un dato existente como centroide se minimiza el error introducido por los &lt;em&gt;outliers&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Cuando se tratan datos no numéricos, es posible usar k-modes. Esta variación del algoritmo escoge como centroide el valor de moda en el conjunto. El punto fuerte de esta técnica es que es muy robusto a &lt;em&gt;outliers&lt;/em&gt;.&lt;/p&gt;
&lt;h4 id=&#34;pre-y-post-procesamiento-requeridoa-idsec-1-3-1-6-namesec-1-3-1-6a&#34;&gt;&lt;strong&gt;Pre y Post procesamiento requerido&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Debido a que K-Means usa distancias, es necesario normalizar los datos para que todas contribuyan en igual medida, de lo contrario los atributos con mayores magnitudes tienen a dominar las decisiones del algoritmo.&lt;/p&gt;
&lt;p&gt;En cuanto al post procesamiento, es posible eliminar &lt;em&gt;clusters&lt;/em&gt; demasiado pequeños, y tratarlos como &lt;em&gt;clusters outliers&lt;/em&gt;, dividir &lt;em&gt;clusters&lt;/em&gt; con un elevado SSE en varios o combinar aquellos con un SSE bajo.&lt;/p&gt;
&lt;h3 id=&#34;dbscana-idsec-1-3-2-namesec-1-3-2a&#34;&gt;DBSCAN&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h3&gt;
&lt;p&gt;Este algoritmo es de la familia jerárquica del &lt;em&gt;clustering&lt;/em&gt;, concretamente &lt;strong&gt;basado en densidad&lt;/strong&gt;. Su principal característica es detectar regiones de puntos densas separadas de otras regiones poco densas. Al contrario que K-Means, detecta automáticamente el número de &lt;em&gt;clusters&lt;/em&gt;. Debido a que las regiones poco densas son descartadas, no produce un &lt;em&gt;clustering&lt;/em&gt; completo, es decir, habrá puntos sin clasificar.&lt;/p&gt;
&lt;p&gt;DBSCAN está basado en una aproximación basada en el centro. Consiste en medir la densidad como el número de puntos que caen dentro de un radio especificado. El radio por tanto, es un parámetro del algoritmo que se debe ajustar. Una vez definido el radio, un punto puede caer en el interior de una región densa, en el borde o completamente fuera. A estos puntos se les llama puntos &lt;em&gt;core&lt;/em&gt;, &lt;em&gt;border&lt;/em&gt; o &lt;em&gt;noise&lt;/em&gt;, respectivamente ( en español Principales, frontera o ruido). La figura muestra un ejemplo de cada uno de ellos.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core Points&lt;/strong&gt;: Corresponden a los puntos dentro de la región densa. Para ser un punto &lt;em&gt;core&lt;/em&gt; debe haber un número mínimo de puntos definidos como parámetro en su vecindario, que viene dado por el radio.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Border Points&lt;/strong&gt;: Aunque no es un &lt;em&gt;core point&lt;/em&gt;, cae en el entorno de un &lt;em&gt;core point&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Noise Points&lt;/strong&gt;: Un punto que no es ni &lt;em&gt;core&lt;/em&gt; ni &lt;em&gt;border&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;descipción-del-algoritmoa-idsec-1-3-2-1-namesec-1-3-2-1a&#34;&gt;&lt;strong&gt;Descipción del algoritmo&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Para cualquier par de puntos &lt;em&gt;core&lt;/em&gt; lo suficientemente cercanos entre sí – dentro de un radio definido – se colocan en el mismo &lt;em&gt;cluster&lt;/em&gt;. Análogamente, cualquier punto &lt;em&gt;border&lt;/em&gt; cercano a un &lt;em&gt;core&lt;/em&gt; se asigna al mismo &lt;em&gt;cluster&lt;/em&gt; del &lt;em&gt;core&lt;/em&gt;. Los puntos de ruido, se descartan, por ello se indicó en el párrafo anterior que DBSCAN no es un &lt;em&gt;clustering&lt;/em&gt; completo.&lt;/p&gt;
&lt;h4 id=&#34;selección-de-parámetrosa-idsec-1-3-2-2-namesec-1-3-2-2a&#34;&gt;&lt;strong&gt;Selección de parámetros&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;DBSCAN necesita de dos parámetros antes de ser ejecutado, &lt;em&gt;MinPts&lt;/em&gt; y &lt;em&gt;Eps&lt;/em&gt;, definiendo el número mínimo de puntos necesarios para considerar a un punto como &lt;em&gt;core&lt;/em&gt; y el radio, respectivamente. Lo más usual es observar cómo evoluciona la distancia de un punto a sus k-ésismos vecinos más cercanos (k-distancia). Para los puntos que forman parte de un &lt;em&gt;cluster&lt;/em&gt;, el valor k-distancia será pequeño si &lt;em&gt;k&lt;/em&gt; no es mayor que el tamaño del &lt;em&gt;cluster&lt;/em&gt;. Para los puntos que no pertenecen al &lt;em&gt;cluster&lt;/em&gt;, la k-distancia será elevada. Por tanto, de forma visual es posible determinar el valor del parámetro &lt;em&gt;Eps&lt;/em&gt;, como muestra la figura, y tomando el valor de &lt;code&gt;k&lt;/code&gt; como &lt;em&gt;MinPts&lt;/em&gt;.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h4 id=&#34;pros-y-contras-de-dbscana-idsec-1-3-2-3-namesec-1-3-2-3a&#34;&gt;&lt;strong&gt;Pros y Contras de DBSCAN&lt;/strong&gt;.&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h4&gt;
&lt;p&gt;Que DBSCAN al use una aproximación basada en densidad le proporciona resistencia al ruido y es capaz de trabajar con &lt;em&gt;clusters&lt;/em&gt; de tamaños y formas arbitrarias, por tanto puede encontrar &lt;em&gt;clusters&lt;/em&gt; que K-Means no podría. Sin embargo, DBSCAN encuentra dificultades al trabajar con &lt;em&gt;clusters&lt;/em&gt; de distintas densidades. De igual manera, no funciona bien cuando los datos son de gran dimensionalidad, ya que medir la densidad en espacios de gran dimensión es difícil.&lt;/p&gt;
&lt;h2 id=&#34;evaluación-de-resultadosa-idsec-1-4-namesec-1-4a&#34;&gt;Evaluación de resultados&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h2&gt;
&lt;p&gt;Para la evaluación del resultado de un &lt;em&gt;clustering&lt;/em&gt; es necesario tener en cuenta varios aspectos, entre ellos:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determinar la &lt;strong&gt;tendencia del &lt;em&gt;clustering&lt;/em&gt;&lt;/strong&gt;, es decir, distinguir si realmente existe una estructura no aleatoria en los datos.&lt;/li&gt;
&lt;li&gt;Determinar el número correcto de &lt;em&gt;clusters&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Evaluar si realmente el resultado del &lt;em&gt;clustering&lt;/em&gt; corresponde con los patrones de los datos, sin referenciar a información externa (&lt;strong&gt;Criterios internos&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Comparar los resultados del &lt;em&gt;clustering&lt;/em&gt; usando información externa, como etiquetas de las clases (&lt;strong&gt;criterios externos&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Comprar dos conjuntos de &lt;em&gt;clusters&lt;/em&gt; y determinar cual es mejor.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Debido a que las técnicas 1,2 y 3 no usan información externa, son técnicas &lt;strong&gt;no supervisadas&lt;/strong&gt;, la cuarta sin embargo necesita información externa, y por tanto es &lt;strong&gt;supervisada&lt;/strong&gt;. La quita puede considerarse un híbrido, ya que puede realizarse de forma supervisada o no supervisada.&lt;/p&gt;
&lt;p&gt;Las &lt;strong&gt;técnicas no supervisadas&lt;/strong&gt; tratan me medir si la estructura del &lt;em&gt;clustering&lt;/em&gt; es adecuada sin información externa. Un ejemplo de ello es mediante el uso de SSE. Usando esta medida es posible definir la &lt;strong&gt;cohesión&lt;/strong&gt; del &lt;em&gt;cluster&lt;/em&gt;, la cual determina cómo están de juntos los puntos del &lt;em&gt;cluster&lt;/em&gt; así como la &lt;strong&gt;separación&lt;/strong&gt;, que mide cómo de separado está un &lt;em&gt;cluster&lt;/em&gt; con respecto a otro. Para realizar estas mediciones pueden usarse o no los centroides, como muestra la figura.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;En cuanto a las &lt;strong&gt;técnicas supervisadas&lt;/strong&gt;, usando información externa, como por ejemplo datos etiquetados, mide hasta qué punto el &lt;em&gt;clustering&lt;/em&gt; consiguió descubrir la estructura de los datos. Un ejemplo de este tipo de técnica es la &lt;strong&gt;entropía&lt;/strong&gt;, la cual mide cómo de bien coinciden las etiquetas de los &lt;em&gt;clusters&lt;/em&gt; con unos datos etiquetados previamente.&lt;/p&gt;
&lt;p&gt;Por último, comparar dos conjuntos de &lt;em&gt;clusterings&lt;/em&gt; puede hacerse de forma supervisada o no supervisada. Por ejemplo, lanzar dos veces K-Means y compararlos usando SSE o entropía.&lt;/p&gt;
&lt;h1 id=&#34;erratas&#34;&gt;Erratas&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Gracias a &lt;a href=&#34;https://gitlab.com/josealberto4444&#34; title=&#34;Enlace al gitlab de JoseAlberto4444&#34;&gt;@josealberto4444&lt;/a&gt; por resaltar que faltaba la propiedad de no negatividad en las distancias.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;bibliografía-a-idsec-5-namesec-5a&#34;&gt;Bibliografía &lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2F04PCT&#34;&gt;Cap 8. Introduction to Data Mining 1st edition by Tan, Pang-Ning, Steinbach, Michael, Kumar, Vipin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://amzn.to/2sYPCAl&#34;&gt;Data Mining, Southeast Asia Edition: Concepts and Techniques (The Morgan Kaufmann Series in Data Management Systems)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Minkowski_distance&#34;&gt;https://en.wikipedia.org/wiki/Minkowski_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Euclidean_distance&#34;&gt;https://en.wikipedia.org/wiki/Euclidean_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Taxicab_geometry&#34;&gt;https://en.wikipedia.org/wiki/Taxicab_geometry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Chebyshev_distance&#34;&gt;https://en.wikipedia.org/wiki/Chebyshev_distance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Apuntes de clase &lt;em&gt;Aprendizaje no supervisado y detección de anomalías&lt;/em&gt; del &lt;strong&gt;Máster universitario en Ciencia de Datos e Ingeniería de Computadores de la Universidad de Granada&lt;/strong&gt;*&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>Mostrar artículos similares usando Clustering con sklearn</title>
            <link>https://elbauldelprogramador.com/mostar-articulos-relacionados-blog/</link>
            <pubDate>Tue, 31 Oct 2017 19:58:04 +0200</pubDate>
            
            <guid>https://elbauldelprogramador.com/mostar-articulos-relacionados-blog/</guid>
            <description>&lt;p&gt;
Hace un tiempo quería mostrar &lt;strong&gt;artículos similares / relacionados&lt;/strong&gt; al final de cada artículo de este blog. Al momento de plantear este problema, &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; no tenía soporte para esta característica, hoy día sí. Para ello decidí implementar mi propio sistema usando &lt;a href=&#34;https://elbauldelprogramador.com/tags/python/&#34;&gt;python&lt;/a&gt;, &lt;em&gt;sklearn&lt;/em&gt; y &lt;a href=&#34;https://es.wikipedia.org/wiki/An%C3%A1lisis_de_grupos&#34;&gt;Clustering&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
&amp;lt;figure&amp;gt;
        &amp;lt;a href=&amp;#34;/img/clustering-similar-posts-sklearn-python.jpg&amp;#34;&amp;gt;
          &amp;lt;img
            on=&amp;#34;tap:lightbox1&amp;#34;
            role=&amp;#34;button&amp;#34;
            tabindex=&amp;#34;0&amp;#34;
            layout=&amp;#34;responsive&amp;#34;
            src=&amp;#34;/img/clustering-similar-posts-sklearn-python.jpg&amp;#34;
            alt=&amp;#34;Agrupando artículos similares&amp;#34;
            title=&amp;#34;Agrupando artículos similares&amp;#34;
            sizes=&amp;#34;(min-width: 640px) 640px, 100vw&amp;#34;
            width=&amp;#34;640&amp;#34;
            height=&amp;#34;437&amp;#34;&amp;gt;
          &amp;lt;/img&amp;gt;
        &amp;lt;/a&amp;gt;
&amp;lt;/figure&amp;gt;
&lt;/p&gt;
&lt;h2 id=&#34;headline-1&#34;&gt;
Diseño del programa
&lt;/h2&gt;
&lt;h3 id=&#34;headline-2&#34;&gt;
Leer y Parsear los artículos
&lt;/h3&gt;
&lt;p&gt;
Ya que escribo tanto en &lt;a href=&#34;https://elbauldelprogramador.com/en/&#34;&gt;Inglés&lt;/a&gt; y &lt;a href=&#34;https://elbauldelprogramador.com&#34;&gt;Español&lt;/a&gt;, necesito entrenar el modelo dos veces, para poder mostrar artículos relacionados en inglés a los lectores ingleses, y en Castellano a los Hispanos. La función &lt;code class=&#34;verbatim&#34;&gt;readPosts&lt;/code&gt; se encarga de esto. Recibe como argumentos el &lt;em&gt;directorio&lt;/em&gt; donde se encuentran los artículos, y un &lt;code class=&#34;verbatim&#34;&gt;booleano&lt;/code&gt; indicando si quiero leer los escritos en inglés o castellano.
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;dfEng&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;readPosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;blog/content/post&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                  &lt;span class=&#34;n&#34;&gt;english&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dfEs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;readPosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;blog/content/post&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                 &lt;span class=&#34;n&#34;&gt;english&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;False&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Dentro de esta función (&lt;a href=&#34;https://github.com/elbaulp/hugo_similar_posts/blob/master/similar_posts.py#L63&#34;&gt;puedes consultarla en mi github&lt;/a&gt;), leo los artículos y devuelvo un &lt;a href=&#34;http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html&#34;&gt;Data Frame de Pandas&lt;/a&gt;. Lo más relevante que hace esta función es seleccionar el &lt;a href=&#34;https://elbauldelprogramador.com/tags/parser/&#34;&gt;parser correcto&lt;/a&gt;, para abrir los ficheros usando el &lt;a href=&#34;https://elbauldelprogramador.com/how-to-parse-frontmatter-with-python/&#34;&gt;parseador de yaml&lt;/a&gt; o el de &lt;em&gt;TOML&lt;/em&gt;. Una vez leido el &lt;em&gt;frontmatter&lt;/em&gt;, &lt;code class=&#34;verbatim&#34;&gt;readPosts&lt;/code&gt; crea el &lt;strong&gt;DataFrame&lt;/strong&gt; usando estos &lt;em&gt;metadatos&lt;/em&gt;. En concreto solo se queda con estos:
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;n&#34;&gt;tags&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;tags&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;introduction&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s1&#34;&gt;&amp;#39;description&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
Lo cual significa, que usaremos esta información para clasificar los posts.
&lt;/p&gt;
&lt;p&gt;
&amp;lt;!–ad–&amp;gt;
&lt;/p&gt;
&lt;h2 id=&#34;headline-3&#34;&gt;
Selección del Modelo
&lt;/h2&gt;
&lt;p&gt;
Como dije al principio, decidí usar &lt;em&gt;Clustering&lt;/em&gt;. Ya que estoy tratando con datos de texto, necesito una forma de convertir esta información a forma numérica. Para conseguirlo se usa una técnica llamada &lt;a href=&#34;https://es.wikipedia.org/wiki/Tf-idf&#34;&gt;TF-IDF (&lt;em&gt;Term frequency – Inverse document frequency&lt;/em&gt;)&lt;/a&gt;. No entraré en los detalles, pero daré una pequeña introducción.
&lt;/p&gt;
&lt;h3 id=&#34;headline-4&#34;&gt;
¿Qué es TF-IDF? (frecuencia de término – frecuencia inversa de documento)
&lt;/h3&gt;
&lt;p&gt;
Cuando se trabaja con &lt;strong&gt;datos de texto&lt;/strong&gt;, muchas palabras aparecen &lt;em&gt;muchas veces en distintos ducumentos pertenecientes a distintas clases&lt;/em&gt;, dichas palabras no suelen contener &lt;strong&gt;información discriminatoria&lt;/strong&gt;. &lt;strong&gt;TF-IDF&lt;/strong&gt; se encarga de rebajar el peso que tienen estos términos en los datos, para que no influyan en la clasificación.
&lt;/p&gt;
&lt;p&gt;
&lt;em&gt;tf-idf&lt;/em&gt; se define como el producto de:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;strong&gt;Frecuencia del término&lt;/strong&gt;. Número de veces que aparece el término en el documento.
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;strong&gt;Frecuencia Inversa de Documento&lt;/strong&gt;. Cuanta información proporciona el término teniendo en cuenta el resto de documentos, es decir, si el término es frecuente o no en el resto de documentos.
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Al multiplicar ambos, obtenemos el &lt;em&gt;tf-idf&lt;/em&gt;, citando Wikipedia:
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
Un peso alto en tf-idf se alcanza con una elevada frecuencia de término (en el documento dado) y una pequeña frecuencia de ocurrencia del término en la colección completa de documentos. Como el cociente dentro de la función logaritmo del idf es siempre mayor o igual que 1, el valor del idf (y del tf-idf) es mayor o igual que 0. Cuando un término aparece en muchos documentos, el cociente dentro del logaritmo se acerca a 1, ofreciendo un valor de idf y de tf-idf cercano a 0.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
En resumen, conforme &lt;strong&gt;más común es un término entre todos los documentos&lt;/strong&gt;, menor será el valor &lt;em&gt;tf-idf&lt;/em&gt;, lo cual indica que esa palabra no es importante para la clasificación.
&lt;/p&gt;
&lt;h3 id=&#34;headline-5&#34;&gt;
Hiperparámetros
&lt;/h3&gt;
&lt;p&gt;
Para seleccionar los parámetros apropiados para el modelo he usado &lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34;&gt;el método GridSearchCV de sklearn&lt;/a&gt;, puedes verlo en &lt;a href=&#34;https://github.com/elbaulp/hugo_similar_posts/blob/master/similar_posts.py#L425&#34;&gt;la línea 425 del código&lt;/a&gt;.
&lt;/p&gt;
&lt;h2 id=&#34;headline-6&#34;&gt;
Limpiando los datos
&lt;/h2&gt;
&lt;p&gt;
Con el método a usar (&lt;em&gt;clustering&lt;/em&gt;) y teniendo los datos de texto en formato numérico (&lt;em&gt;TF-IDF&lt;/em&gt;), ahora toca limpiar los datos. Cuando se trabaja con datos de texto, es muy frecuente eliminar lo que se denominan &lt;em&gt;stop words&lt;/em&gt;, palabras que no añaden significado alguno (el, la, los, con, a, eso…). Para ello creo la función &lt;a href=&#34;https://github.com/elbaulp/hugo_similar_posts/blob/master/similar_posts.py#L155&#34;&gt;generateTfIdfVectorizer&lt;/a&gt;. Esta misma función se encarga de realizar el &lt;em&gt;stemming&lt;/em&gt;. De &lt;em&gt;Wikipedia&lt;/em&gt;, &lt;a href=&#34;https://es.wikipedia.org/wiki/Stemming&#34;&gt;Stemming es el proceso de:&lt;/a&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
reducir una palabra a su raíz o (en inglés) a un stem.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
Dependiendo de en qué idioma esté generando los &lt;strong&gt;artículos relacionados&lt;/strong&gt; (inglés o Castellano) uso:
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;tokenizer_snowball&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;stemmer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SnowballStemmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;spanish&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stemmer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
para Castellano o
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;k&#34;&gt;def&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;tokenizer_porter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;porter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PorterStemmer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;porter&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stem&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;word&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;word&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;ow&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;stop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
para inglés.
&lt;/p&gt;
&lt;p&gt;
Tras este proceso, finalmente tengo todos los datos listos para aplicar &lt;em&gt;clustering&lt;/em&gt;.
&lt;/p&gt;
&lt;h2 id=&#34;headline-7&#34;&gt;
Clustering
&lt;/h2&gt;
&lt;p&gt;
He usado &lt;em&gt;KMeans&lt;/em&gt; para realizar el clustering. La mayor carga de trabajo de este proceso era &lt;strong&gt;limpiar los datos&lt;/strong&gt;, así que este paso es sencillo de programar. Solo es necesario saber cuantos &lt;em&gt;clusters&lt;/em&gt; debería tener. Para ello he usado un método llamado &lt;strong&gt;Elbow Method&lt;/strong&gt; (El método del codo). Sirve para hacernos una idea del valor óptimo de &lt;code class=&#34;verbatim&#34;&gt;k&lt;/code&gt; (Cuantos clusters). El metodo nos indica cuando la &lt;strong&gt;distorsión&lt;/strong&gt; entre clusters empieza a aumentar rápidamente. Se muestra mejor con una imagen:
&lt;/p&gt;
&lt;p&gt;
&amp;lt;figure&amp;gt;
        &amp;lt;a href=&amp;#34;/img/Elbow method for clustering.jpg&amp;#34;&amp;gt;
          &amp;lt;img
            on=&amp;#34;tap:lightbox1&amp;#34;
            role=&amp;#34;button&amp;#34;
            tabindex=&amp;#34;0&amp;#34;
            layout=&amp;#34;responsive&amp;#34;
            src=&amp;#34;/img/Elbow method for clustering.jpg&amp;#34;
            alt=&amp;#34;Elbow method&amp;#34;
            title=&amp;#34;Elbow method&amp;#34;
            sizes=&amp;#34;(min-width: 640px) 640px, 100vw&amp;#34;
            width=&amp;#34;640&amp;#34;
            height=&amp;#34;546&amp;#34;&amp;gt;
          &amp;lt;/img&amp;gt;
        &amp;lt;/a&amp;gt;
        &amp;lt;figcaption&amp;gt;En este ejemplo, se aprecia un codo en k=12&amp;lt;/figcaption&amp;gt;
&amp;lt;/figure&amp;gt;
&lt;/p&gt;
&lt;p&gt;
Tras ejecutar el modelo, usando &lt;em&gt;16 características&lt;/em&gt;, estas son las seleccionadas para Catellano:
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;andro&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;comand&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;curs&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;dat&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;desarroll&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;funcion&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;googl&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;jav&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;libr&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;linux&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;program&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;recurs&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;script&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;segur&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;wordpress&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
y para inglés:
&lt;/p&gt;
&lt;div class=&#34;src src-python&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;blogs&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;chang&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;channels&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;curat&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;error&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;fil&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;gento&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;howt&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;list&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;lists&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;podcasts&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;python&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;scal&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;scienc&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;script&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;sa&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;youtub&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;headline-8&#34;&gt;
Cómo intregrar el resultado con Hugo
&lt;/h2&gt;
&lt;p&gt;
Esta parte me llevó bastante tiempo ya que es necesario leer el resultado del modelo, en formato CSV, y mostrar 10 artículos del mismo cluster. Aunque ya no estoy usando este método (ahora uso el propio de Hugo), lo dejo por aquí como referencia:
&lt;/p&gt;
&lt;div class=&#34;src src-go&#34;&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;delimit&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;slice&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;static/&amp;#34;&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;labels.&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Lang&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;.csv&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sep&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;,&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;file&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;File&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;LogicalName&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/* First iterate thought csv to get post cluster */&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;getCSV&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sep&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
   &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
       &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Scratch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Set&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
   &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;cluster&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Scratch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Get&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/* loop csv again to store post in the same cluster */&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;getCSV&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sep&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;url&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;cluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Scratch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Add&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;posts&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;slice&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;post&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Scratch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Get&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;posts&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;

&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;/* Finally, show 5 randomly related posts */&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;gt&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;len&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;{{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;T&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;related&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&amp;lt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;h1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;first&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;shuffle&lt;/span&gt; &lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;li&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;related-post&amp;#34;&lt;/span&gt;  &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;printf&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;href=%q&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Ref&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;safeHTMLAttr&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;printf&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;title=%q&amp;#34;&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;safeHTMLAttr&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&amp;gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&amp;lt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;li&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ul&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;{{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;end&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;em&gt;Si tienes algún comentario, o quiere mejorar algo, comenta abajo.&lt;/em&gt;
&lt;/p&gt;
&lt;h2 id=&#34;headline-9&#34;&gt;
Referencias
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;http://amzn.to/2fJVjwk&#34;&gt;Libro Python Machine Learning&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;a href=&#34;http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html&#34;&gt;Documentación de Sklearn&lt;/a&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>Minería en tu comunidad de github con R - Analizando la popularidad de los lenguajes</title>
            <link>https://elbauldelprogramador.com/githubmininglanguages/</link>
            <pubDate>Tue, 25 Apr 2017 18:34:49 +0200</pubDate>
            
            <guid>https://elbauldelprogramador.com/githubmininglanguages/</guid>
            <description>&lt;p&gt;En este post vamos a explorar nuestra comunidad de &lt;a href=&#34;https://elbauldelprogramador.com/tags/git/&#34; title=&#34;Github&#34;&gt;Github&lt;/a&gt;, considerando nuestros amigos (nuestros seguidores) en esta red social. En primer lugar daremos algunas indicaciones para crear una aplicación y empezar a usar la &lt;a href=&#34;https://elbauldelprogramador.com/tags/api/&#34; title=&#34;API&#34;&gt;API&lt;/a&gt;  de github. Después extraeremos la información que necesitamos para realizar nuestro análisis, y así obtener que lenguajes de programación son más usados por nuestros amigos, y cuales los menos usados. ¡Exploremos la popularidad de los lenguajes en nuestra comunidad!&lt;/p&gt;
&lt;h1 id=&#34;1-crear-la-app-instalar-paquetes-autenticarse&#34;&gt;1. Crear la app, instalar paquetes, autenticarse&lt;/h1&gt;
&lt;h2 id=&#34;11-registrar-la-app&#34;&gt;1.1 Registrar la app&lt;/h2&gt;
&lt;p&gt;Antes de nada, ya que queremos acceder a datos públicos de github, ncesitaremos registrar una app con autenticación para ello. Esto nos permitirá no tener límite de llamadas a la API.
Así que dirígete a &lt;a href=&#34;https://developer.github.com/program/&#34; title=&#34;la página del programa de desarrolladores de github&#34;&gt;github developer program page&lt;/a&gt; y clica en &lt;strong&gt;Register now&lt;/strong&gt;. Luego, selecciona una cuenta (debe aparecer un listado de tus cuentas de github) y en la pestaña de &lt;strong&gt;Personal settings&lt;/strong&gt; selecciona  &lt;strong&gt;Authorized applications&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Si ya tienes una aplicación autorizada para acceder a la API de github, deberás visualizarla aquí.  Sino tienes ninguna app registrada aún, vete a &lt;strong&gt;OAuth applications&lt;/strong&gt; (bajo &lt;em&gt;Personal settings&lt;/em&gt;) y selecciona &lt;strong&gt;Register a new application&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Ahora tienes que registrar tu nueva app, darle un nombre, una descripción&amp;hellip; completa los campos y en &lt;strong&gt;Callback URL&lt;/strong&gt; introduce: &lt;a href=&#34;http://localhost:1410/&#34; title=&#34;localhost:1410&#34;&gt;localhost:1410&lt;/a&gt;, que es la url a la que github devolverá cuando se autentique la app.&lt;/p&gt;
&lt;p&gt;Ahora que tienes registrada tu app, se generarán su &lt;strong&gt;Client ID&lt;/strong&gt; y &lt;strong&gt;Client Secret&lt;/strong&gt;. Puedes verlos en &lt;strong&gt;OAuth applications -&amp;gt; Your App&lt;/strong&gt;. Recuerda mantenerlos siempre en secreto y a salvo.&lt;/p&gt;
&lt;p&gt;¡Bien! pues ya eres miembro del programa de &lt;em&gt;developers&lt;/em&gt;. Lo siguiente que haremos es instalar los paquetes de &lt;a href=&#34;https://elbauldelprogramador.com/tags/r/&#34; title=&#34;R&#34;&gt;R&lt;/a&gt; que vamos a usar para trabajar.&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h2 id=&#34;12-instalación-de-paquetes&#34;&gt;1.2 Instalación de paquetes&lt;/h2&gt;
&lt;p&gt;Usaremos la versión 3 de la API de GitHub para obtener los datos &lt;a href=&#34;https://developer.github.com/v3/&#34; title=&#34;github v3 API&#34;&gt;github v3 API&lt;/a&gt;. Ya que la API devuelve los datos en formato &lt;a href=&#34;https://elbauldelprogramador.com/tags/json/&#34; title=&#34;JSON&#34;&gt;JSON&lt;/a&gt;, vamos a usar la función &lt;code&gt;fromJSON&lt;/code&gt;, que nos permitirá usar la url de la API directamente y nos parsea los datos JSON devueltos en formato &lt;em&gt;dataframe&lt;/em&gt;. Ésta función se encuentra en el paquete &lt;code&gt;jsonlite&lt;/code&gt;, así que tenemos que instalar ese paquete si no lo tenemos ya instalado:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;nf&#34;&gt;install.packages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;jsonlite&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Si no tienes instalado el paquete &lt;code&gt;stringr&lt;/code&gt;, instálalo tal como acabamos de hacer con &lt;code&gt;jsonlite&lt;/code&gt;. Lo usaremos para hacer operaciones comunes con &lt;em&gt;strings&lt;/em&gt;. Instala también &lt;code&gt;ggplot2&lt;/code&gt; si no lo tienes instalado. Lo usaremos para las gráficas y &lt;code&gt;httpuv&lt;/code&gt;, un paquete para poder trabajar con HTTP.&lt;/p&gt;
&lt;p&gt;Para conectarse a la app the github, necesitaremos instalar el paquete &lt;code&gt;rgithub&lt;/code&gt;. Puedes hacerlo directamente desde el código fuente en github. Date cuenta que depende del paquete &lt;code&gt;devtools&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;nf&#34;&gt;require&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;devtools&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;install_github&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;cscheid/rgithub&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Tras la instalación, carga las librerías:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# load libraries&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;github&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;jsonlite&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;stringr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;library&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ggplot2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;13-autentica-el-acceso&#34;&gt;1.3 Autentica el acceso&lt;/h2&gt;
&lt;p&gt;Necesitaremos &lt;a href=&#34;https://elbauldelprogramador.com/tags/seguridad/&#34; title=&#34;Post sobre seguridad&#34;&gt;autenticar&lt;/a&gt; el acceso, y lo haremos a través de la función &lt;code&gt;interactive.login&lt;/code&gt; del paquete &lt;code&gt;rgithub&lt;/code&gt;, pasándole nuestro &lt;strong&gt;ID&lt;/strong&gt; y &lt;strong&gt;secreto&lt;/strong&gt;. Mi recomendación es que pongas estas líneas en un fichero separado y no las compartas con nadie. Sólo haz un &lt;em&gt;source&lt;/em&gt; del fichero cuando necesites autenticarte o ejecuta las líneas de nuevo.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# github app autentication&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;clientID&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;your_client_id_goes_here&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;clientSecret&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;your_secret_goes_here&amp;#34;&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;interactive.login&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clientID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clientSecret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;2-obtener-la-información-de-tus-amigos&#34;&gt;2. Obtener la información de tus amigos&lt;/h1&gt;
&lt;p&gt;Ya estás autenticado. Lo que sigue es obtener tus seguidores de GitHub. Para obtener los usuarios que nos siguen e información sobre ellos, usaremos la función &lt;code&gt;get.my.followers&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# get your followers&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;get.my.followers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Podemos comprobar fácilmente cuantos seguidores tenemos usando la función &lt;code&gt;length&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# get number of my followers&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;numFollowing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ahora que tenemos nuestros seguidores, vamos a crear un &lt;em&gt;dataframe&lt;/em&gt; para guardar toda la información obtenida. Primero, extraemos cada línea de contenido de la lista de &lt;em&gt;myFollowers&lt;/em&gt;, y la vamos añadiendo a una variable &lt;em&gt;dataset&lt;/em&gt; usando la función &lt;code&gt;rbind&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# create a dataset with your followers&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;unlist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content[[1]]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;nf&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)){&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;unlist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content[[i]]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ahora que tenemos el &lt;em&gt;dataframe&lt;/em&gt;, nombra a las columnas como se llamaban originalmente en &lt;em&gt;myFollowers$content&lt;/em&gt; y guárdalo en un &lt;em&gt;csv&lt;/em&gt; para poder reutilizarlo:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# create a data frame and save it for later use&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;unname&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.data.frame&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;colnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;names&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFollowers&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content[[1]]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;write.csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dataset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;file&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;CrisFollowers.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Obviamente lo puedes guardar con el nombre que quieras. Pero no olvides la extensión.&lt;/p&gt;
&lt;h1 id=&#34;3-obtener-la-información-de-los-repositorios-de-tus-amigos-y-crear-un-nuevo-conjunto-de-datos&#34;&gt;3. Obtener la información de los repositorios de tus amigos y crear un nuevo conjunto de datos&lt;/h1&gt;
&lt;p&gt;Como ya te habrás percatado, en los últimos datos que extraímos había información acerca del nombre de nuestros seguidores, su id, avatar, tipo&amp;hellip; y algunas url de interés. Sin embargo, en esa información no aparecía la información de los repositorios que necesitamos para nuestro análisis, como nombres de los repositorios, lenguaje de los repositorios, número de líneas de código&amp;hellip;&lt;/p&gt;
&lt;p&gt;Debemos obtener esa información. Si has explorado un poco el dataset, te habrás dado cuenta de que existe una columna, llamada  &lt;strong&gt;repos_url&lt;/strong&gt; que nos dice que la url para obtener los repositorios dado un usuario cualquiera, es: __&lt;a href=&#34;https://api.github.com/users/user/repos__&#34;&gt;https://api.github.com/users/user/repos__&lt;/a&gt;. Por ejemplo, para obtener la información de cuales son mis repositorios, etc, deberemos llamar a la API  __&lt;a href=&#34;https://api.github.com/users/CritinaHG/repos__&#34;&gt;https://api.github.com/users/CritinaHG/repos__&lt;/a&gt; , y obtendremos los datos que queremos en formato JSON.&lt;/p&gt;
&lt;p&gt;Así que obtendremos esos datos para cada usuario leyendo el dataset que creamos anteriormente, obteniendo de él los nombres de nuestros seguidores, componiendo la correspondiente url de sus repos y parseando los datos obtenidos de la API usando la función &lt;code&gt;fromJSON&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# read latest created csv&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;myFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;read.csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;CrisFollowers.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# extract the names&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;unname&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.character&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;login&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# extract data from friends&amp;#39; public repositories&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;compdata&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;NULL&lt;/span&gt;

&lt;span class=&#34;nf&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;nrow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;myFriends&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)){&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;fromJSON&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;paste0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;https://api.github.com/users/&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;str_trim&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unname[i]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;side&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;both&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/repos?clientID&amp;amp;clientSecret&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
  &lt;span class=&#34;nf&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;length&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;-4&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;n&#34;&gt;compdata&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;rbind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;compdata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# write data for reuse&lt;/span&gt;
&lt;span class=&#34;nf&#34;&gt;write.csv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;compdata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;UsersWithRepoInfo.csv&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Debes sustituir &lt;strong&gt;clientID&lt;/strong&gt; y &lt;strong&gt;clientSecret&lt;/strong&gt; por el id y secreto de tu app, generados al principio del post. No es necesario especificarle estos parámetros, pero hacerlo nos permite evitar limitaciones en las peticiones. Se elimina la 4º columna porque contiene información redundante, y se usa &lt;code&gt;rbind&lt;/code&gt; para ir agregando los datos que se van obteniendo al nuevo &lt;em&gt;dataset&lt;/em&gt;.&lt;/p&gt;
&lt;h1 id=&#34;4-haciendo-un-poco-de-procesamiento&#34;&gt;4. Haciendo un poco de procesamiento&lt;/h1&gt;
&lt;p&gt;Lee (si no tienes leído) el &lt;em&gt;dataset&lt;/em&gt; &lt;code&gt;activeFriends&amp;lt;-read.csv(&amp;quot;UsersWithRepoInfo.csv&amp;quot;)&lt;/code&gt;. Vamos a hacerle algunas transformaciones a los datos para hacerlos más manejables con R.&lt;/p&gt;
&lt;p&gt;En primer lugar, como la zona horaria es UTC+2 (o la de Madrid), necesitamos establecer el parámetro timezone. Construimos una función para realizar el formateo y lo aplicamos a cada columna con fechas del &lt;em&gt;dataset&lt;/em&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# make date format supported by R&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;date.format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datestring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
  &lt;span class=&#34;n&#34;&gt;date&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.POSIXct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;datestring&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;format&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%Y-%m-%d %H:%M:%S&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Europe/Madrid&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;usetz&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# update dates with new format&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;created_at&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;date.format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;created_at&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;updated_at&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;date.format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;updated_at&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pushed_at&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;date.format&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pushed_at&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Siéntete libre de explorar el conjunto de datos. Seguro que estás pensando que en él hay columnas que nos interesan para nuestro análisis, y otras que no tanto. Lo siguiente que haremos será seleccionar las que más nos interesan para nuestro análisis:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# selecting just the interesting cols&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;id&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;full_name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;private&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;description&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;fork&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;created_at&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;updated_at&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;pushed_at&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;homepage&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;size&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;stargazers_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;watchers_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;language&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;                             &lt;span class=&#34;s&#34;&gt;&amp;#34;has_issues&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;has_downloads&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;forks_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;open_issues_count&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;forks&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;open_issues&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;watchers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Podemos binarizar las columnas que tienen solo valores True o False:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;private&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_issues&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_issues&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fork&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_downloads&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.integer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;has_downloads&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Por último, la columna &lt;code&gt;full_name&lt;/code&gt; contiene el nombre de usuario junto con el nombre del repositorio. Extraemos de aquí sólo el nombre de usuario, pues el nombre del repositorio ya se incluye en la columna &lt;code&gt;name&lt;/code&gt;. Lo hacemos separando cada item por la barra que separa los nombres, y tomando el primer elemento:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# Getting the username&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;full_name&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;unlist&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;lapply&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;strsplit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;as.character&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;full_name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;split&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fixed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;TRUE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;function&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x[1]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Guárdalo si quieres, para reutilizarlo más tarde.&lt;/p&gt;
&lt;h1 id=&#34;5-analizando-la-popularidad-de-los-lenguages-de-programación&#34;&gt;5. Analizando la popularidad de los lenguages de programación&lt;/h1&gt;
&lt;p&gt;Podemos hacernos una primera idea de cómo están distribuidos los datos, cual es la media, mediana, máximo, mínimo&amp;hellip; para cada columna, usando la función &lt;code&gt;summary&lt;/code&gt; en el &lt;em&gt;dataset&lt;/em&gt;.
Éste es sólo un ejemplo parte de la salida de esta función que se obtiene para mi comunidad de amigos, mostrando las métricas mencionadas para las primeras columnas:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;nf&#34;&gt;summary&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
       &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;                 &lt;span class=&#34;n&#34;&gt;name&lt;/span&gt;      &lt;span class=&#34;n&#34;&gt;full_name&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;private&lt;/span&gt;                                                                      &lt;span class=&#34;n&#34;&gt;description&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Min.&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2054512&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;IV&lt;/span&gt;      &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Length&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;524&lt;/span&gt;         &lt;span class=&#34;n&#34;&gt;Min.&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Asignatura&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;infraestructuras&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;virtuales&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;para&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;el&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Grado&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Informática&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;
&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;st&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Qu.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;32878832&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;blog&lt;/span&gt;    &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Class&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;character&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;st&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Qu.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Repositorio&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;para&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;la&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;asignatura&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Infraestructura&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Virtual&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;2016-2017&lt;/span&gt;       &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Median&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;51252063&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;DAI&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Mode&lt;/span&gt;  &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;character&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Median&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;An&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;example&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;repo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Ruby&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;continuous&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;integration&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Travis&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;CI&lt;/span&gt;         &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;51191269&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;IV16&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;-17&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;                      &lt;span class=&#34;n&#34;&gt;Mean&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Curso&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;LaTeX&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;organizado&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;por&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;AMAT&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;para&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;alumnos&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Trabajo&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Fin&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Grado&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rd&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Qu.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;70082791&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;swap1415&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;                      &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rd&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Qu.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;Diferentes&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;scripts&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;para&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;representación&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;de&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;carreras&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;en&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cifras&lt;/span&gt;              &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;Max.&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;88848228&lt;/span&gt;   &lt;span class=&#34;n&#34;&gt;TFG&lt;/span&gt;     &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;                      &lt;span class=&#34;n&#34;&gt;Max.&lt;/span&gt;   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;   &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Other&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;                                                                   &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;404&lt;/span&gt;
                   &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Other&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;505&lt;/span&gt;                                  &lt;span class=&#34;kc&#34;&gt;NA&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;s                                                                      :107&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Ahora vamos al tema que nos concierne: ver que lenguajes de programación se están usando en nuestra comunidad de amigos, y cuánto se usan. Para este cometido, podemos comenzar por crear una tabla de contingencia, para dar un primer vistazo a nuestra respuesta:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;n&#34;&gt;languagesAndUse&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;table&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;language&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;languagesAndUse&lt;/span&gt;

         &lt;span class=&#34;n&#34;&gt;Arduino&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;               &lt;span class=&#34;n&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;#              C++            CLIPS              CSS             Dart&lt;/span&gt;
               &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;13&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;55&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;19&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
      &lt;span class=&#34;n&#34;&gt;Emacs&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Lisp&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;GAP&lt;/span&gt;         &lt;span class=&#34;n&#34;&gt;GDScript&lt;/span&gt;               &lt;span class=&#34;n&#34;&gt;Go&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;Groovy&lt;/span&gt;          &lt;span class=&#34;n&#34;&gt;Haskell&lt;/span&gt;             &lt;span class=&#34;n&#34;&gt;HTML&lt;/span&gt;
               &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;48&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;Java&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;JavaScript&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Jupyter&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Notebook&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;Lex&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;Lua&lt;/span&gt;         &lt;span class=&#34;n&#34;&gt;Makefile&lt;/span&gt;      &lt;span class=&#34;n&#34;&gt;Mathematica&lt;/span&gt;
              &lt;span class=&#34;m&#34;&gt;60&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;67&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
             &lt;span class=&#34;n&#34;&gt;PHP&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;PostScript&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;Prolog&lt;/span&gt;           &lt;span class=&#34;n&#34;&gt;Python&lt;/span&gt;                &lt;span class=&#34;n&#34;&gt;R&lt;/span&gt;             &lt;span class=&#34;n&#34;&gt;Ruby&lt;/span&gt;            &lt;span class=&#34;n&#34;&gt;Scala&lt;/span&gt;
               &lt;span class=&#34;m&#34;&gt;8&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;56&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;12&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;24&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
           &lt;span class=&#34;n&#34;&gt;Shell&lt;/span&gt;              &lt;span class=&#34;n&#34;&gt;TeX&lt;/span&gt;       &lt;span class=&#34;n&#34;&gt;TypeScript&lt;/span&gt;
               &lt;span class=&#34;m&#34;&gt;7&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;38&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Con &lt;code&gt;nrow(languagesAndUse)&lt;/code&gt; podemos ver el número de lenguages diferentes que se están usando en nuestra comunidad de amigos. En la mía son 31.
También podemos apreciar que hay muchos repos con código &lt;em&gt;JavaScript&lt;/em&gt;  entre mis 30 amigos, sin embargo, parece que &lt;em&gt;Scala&lt;/em&gt;, &lt;em&gt;Lua&lt;/em&gt;, &lt;em&gt;Arduino&lt;/em&gt;, &lt;em&gt;TypeScript&lt;/em&gt;, &lt;em&gt;Groovy&lt;/em&gt;, &lt;em&gt;Lex&lt;/em&gt;, &lt;em&gt;Prolog&lt;/em&gt;, &lt;em&gt;GDScript&lt;/em&gt;&amp;hellip; sólo son usados por una persona.&lt;/p&gt;
&lt;p&gt;Finalmente, usamos &lt;code&gt;qplot&lt;/code&gt; del paquete &lt;code&gt;ggplot2&lt;/code&gt; para crear un hibstograma que represente el uso de los lenguajes de programación en nuestra comunidad de github:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-r&#34; data-lang=&#34;r&#34;&gt;&lt;span class=&#34;n&#34;&gt;languages&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;na.omit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;activeFriends&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;$&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;language&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;langUssage&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;qplot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;languages&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;geom&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;bar&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;xlab&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Language&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ylab&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Usage&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;fill&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;I&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;cornflowerblue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;n&#34;&gt;langUssage&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;axis.text.x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;element_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;angle&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;90&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hjust&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;ggtitle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Programming languages used by my friends&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;theme&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plot.title&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;element_text&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hjust&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Donde usamos &lt;code&gt;na.omit&lt;/code&gt; para omitir de la representación de los datos los valores NA (lenguajes que no se hayan podido extraer). El hibstograma resultante es el siguiente:&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;Así que, como podemos ver en la representación, &lt;em&gt;JavaScript&lt;/em&gt; es el lenguage más usado, habiendo 67 repos en total en mi comunidad de amigos que contienen código &lt;em&gt;JavaScript&lt;/em&gt;. También &lt;a href=&#34;https://elbauldelprogramador.com/tags/java&#34;&gt;&lt;em&gt;Java&lt;/em&gt;&lt;/a&gt;, &lt;em&gt;C++&lt;/em&gt; y &lt;a href=&#34;https://elbauldelprogramador.com/tags/python&#34;&gt;&lt;em&gt;Python&lt;/em&gt;&lt;/a&gt; son muy populares en mi comunidad.&lt;/p&gt;
&lt;p&gt;Encontramos código &lt;em&gt;Tex&lt;/em&gt; en 38 repositorios, por lo que &lt;a href=&#34;https://elbauldelprogramador.com/tags/latex/&#34;&gt;&lt;em&gt;LaTeX&lt;/em&gt;&lt;/a&gt; está bastante presente en mi comunidad de amigos. También hay muchos repos con código &lt;em&gt;HTML&lt;/em&gt;, y muchos menos con código &lt;em&gt;CSS&lt;/em&gt;, &lt;em&gt;Ruby&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt; and &lt;em&gt;C&lt;/em&gt;. Tras ellos, lenguages conocidos pero no amados por muchos, como &lt;a href=&#34;https://elbauldelprogramador.com/tags/php&#34;&gt;&lt;em&gt;PHP&lt;/em&gt;&lt;/a&gt;, &lt;em&gt;C#&lt;/em&gt; o &lt;em&gt;CLIPS&lt;/em&gt;, que están presentes en menos de 10 repositorios.&lt;/p&gt;
&lt;p&gt;Por último, se puede aprecidar que hay menos de 5 repositorios en total con código &lt;em&gt;Dart&lt;/em&gt;, &lt;em&gt;Go&lt;/em&gt;,&lt;em&gt;Haskell&lt;/em&gt;, &lt;em&gt;Jupyter&lt;/em&gt;, &lt;em&gt;PostScript&lt;/em&gt; y &lt;em&gt;Mathematica&lt;/em&gt;, y que sólo hay un usuario de mi comunidad usando &lt;a href=&#34;https://elbauldelprogramador.com/tags/scala&#34;&gt;&lt;em&gt;Scala&lt;/em&gt;&lt;/a&gt;, &lt;em&gt;Groovy&lt;/em&gt;, &lt;em&gt;Lua&lt;/em&gt; o &lt;em&gt;TypeScript&lt;/em&gt;. Ésto responde a mi pregunta, ya que, como mi lengugaje favorito es Scala, quería saber cuántos de mis seguidores lo usaban.&lt;/p&gt;
&lt;p&gt;Y bueno, ¿Qué sucede en tu comunidad de amigos?
¿Se usan los mismos lenguajes que en la mía? ¿Sigue Siendo JavaScript el más usado?&lt;/p&gt;
&lt;h1 id=&#34;referencias&#34;&gt;Referencias:&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;!-- raw HTML omitted --&gt;Mastering Social Media Mining with R&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
        <item>
            <title>21 Libros Que Debes Leer Para Ser Un Data Scientist O Data Engineer</title>
            <link>https://elbauldelprogramador.com/9-libros-que-debes-leer-para-ser-un-data-scientist-o-data-engineer/</link>
            <pubDate>Sun, 01 Nov 2015 20:30:17 +0000</pubDate>
            
            <guid>https://elbauldelprogramador.com/9-libros-que-debes-leer-para-ser-un-data-scientist-o-data-engineer/</guid>
            <description>&lt;p&gt;Tras mucho buscar, al fin he conseguido recopilar una lista de libros que todo &lt;em&gt;Científico de Datos&lt;/em&gt; o &lt;em&gt;Ingeniero de Datos&lt;/em&gt; debería tener en su
biblioteca personal. Sin más dilaciones, he aquí la lista (La descrición de los libros ha sido cogida de Amazon)&lt;/p&gt;
&lt;h1 id=&#34;para-data-scientist&#34;&gt;Para Data Scientist&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;figure&amp;gt;
  &amp;lt;a href=&amp;quot;/img/ml/pythonmachinelearning.jpg&amp;quot;&amp;gt;
    &amp;lt;img
      on=&amp;quot;tap:lightbox1&amp;quot;
      role=&amp;quot;button&amp;quot;
      tabindex=&amp;quot;0&amp;quot;
      layout=&amp;quot;responsive&amp;quot;
      src=&amp;quot;/img/ml/pythonmachinelearning.jpg&amp;quot;
      alt=&amp;quot;Python Machine Learning book&amp;quot;
      title=&amp;quot;Python Machine Learning book&amp;quot;
      sizes=&amp;quot;(min-width: 380px) 380px, 100vw&amp;quot;
      width=&amp;quot;380&amp;quot;
      height=&amp;quot;468&amp;quot;&amp;gt;
    &amp;lt;/img&amp;gt;
  &amp;lt;/a&amp;gt;
&amp;lt;/figure&amp;gt;



&amp;lt;p&amp;gt;Unlock deeper insights into Machine Leaning with this vital guide to cutting-edge predictive analytics. Leverage Python&#39;s most powerful open-source libraries for deep learning, data wrangling, and data visualization&amp;lt;/p&amp;gt;
&amp;lt;div class=&amp;quot;tags&amp;quot;&amp;gt;
  &amp;lt;a href=&amp;quot;http://amzn.to/2se4MjS&amp;quot; target=&amp;quot;_blank&amp;quot;&amp;gt;Ver en Amazon&amp;lt;/a&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;para-data-engineer&#34;&gt;Para Data Engineer&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;sobre-big-data&#34;&gt;Sobre Big Data&lt;/h1&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;h1 id=&#34;más-libros&#34;&gt;Más libros&lt;/h1&gt;
&lt;p&gt;Si te interesan los libros &lt;em&gt;geek&lt;/em&gt;, visita nuestra recopilación &lt;a href=&#34;https://elbauldelprogramador.com/5-libros-de-no-ficcion-que-todo-geek-deberia-leer/&#34;&gt;16 Libros de No-Ficción que todo Geek debería leer&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;referencias&#34;&gt;Referencias&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.analyticsvidhya.com&#34;&gt;Analyticsvidhya.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
        </item>
        
    </channel>
</rss>
